{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating BMI z-score using Reference Chart from CDC\n",
    "ref: https://www.cdc.gov/growthcharts/extended-bmi-data-files.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_params(subj_age:float, Ref_Chart: pd.DataFrame): \n",
    "    for i in range(len(Ref_Chart) - 1): \n",
    "        start = Ref_Chart['agemos'][i]\n",
    "        end = Ref_Chart['agemos'][i+1]\n",
    "        if subj_age >= start and subj_age < end: \n",
    "            if subj_age <= start + 0.5: \n",
    "                reference_params = Ref_Chart.iloc[i]\n",
    "            elif subj_age > start + 0.5: \n",
    "                reference_params = Ref_Chart.iloc[i+1]\n",
    "        else: \n",
    "            pass \n",
    "    return reference_params  \n",
    "\n",
    "\n",
    "def sds_calculator(BMI, L, M, S): \n",
    "    numerator = (BMI / M) ** L -1   # 분자 \n",
    "    denominator = L * S     # 분모\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def calculating_subj_BMIsds(subj: pd.Series, Ref_Chart: pd.DataFrame) -> float: \n",
    "    age = subj['age']\n",
    "    BMI = subj['BMI']\n",
    "    sex = subj['sex']\n",
    "    sex_Ref_Chart = Ref_Chart[Ref_Chart['sex'] == sex].reset_index(drop=True)\n",
    "    reference_params = get_reference_params(subj_age=age, Ref_Chart=sex_Ref_Chart)\n",
    "    subj_BMIsds = sds_calculator(BMI=BMI, L=reference_params['L'], M=reference_params[\"M\"], S=reference_params[\"S\"])\n",
    "    \n",
    "    P5 = reference_params['P5']\n",
    "    P85 = reference_params['P85']\n",
    "\n",
    "    if BMI <= P5: \n",
    "        status = \"underweight\"\n",
    "    elif BMI > P5 and BMI < P85: \n",
    "        status = \"normal\"\n",
    "    elif BMI >= P85: \n",
    "        status = \"overweight\"\n",
    "    return subj_BMIsds, status\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11493/11493 [00:16<00:00, 703.65it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'BMI_sds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3800'>3801</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3801'>3802</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3802'>3803</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BMI_sds'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m phenotype_tmp \u001b[38;5;241m=\u001b[39m phenotype_tmp\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBMI\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m phenotype_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(phenotype, phenotype_tmp, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubjectkey\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubjectkey\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m phenotype_final \u001b[38;5;241m=\u001b[39m phenotype_final\u001b[38;5;241m.\u001b[39mloc[(\u001b[43mphenotype_final\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBMI_sds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m&\u001b[39m (phenotype_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBMI_sds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m)]\n\u001b[1;32m     23\u001b[0m phenotype_final\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3804'>3805</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3805'>3806</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3806'>3807</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3807'>3808</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3808'>3809</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3801'>3802</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3802'>3803</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3803'>3804</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3804'>3805</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3805'>3806</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3806'>3807</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3807'>3808</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3808'>3809</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BMI_sds'"
     ]
    }
   ],
   "source": [
    "Ref_Chart_dir = '/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/bmi-age-2022.csv'\n",
    "Ref_Chart = pd.read_csv(Ref_Chart_dir)\n",
    "\n",
    "phenotype = pd.read_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total.csv')\n",
    "phenotype_tmp = phenotype[['subjectkey','age', 'sex', 'BMI']] \n",
    "phenotype_tmp = phenotype_tmp.dropna(axis=0)\n",
    "\n",
    "# calculating BMI sds of each subject\n",
    "BMIsds = []\n",
    "BMIstatus = [] \n",
    "\n",
    "for i in tqdm(range(len(phenotype_tmp))): \n",
    "    subj_BMIsds, status = calculating_subj_BMIsds(subj = phenotype_tmp.iloc[i], Ref_Chart=Ref_Chart)\n",
    "    BMIsds.append(subj_BMIsds)\n",
    "    BMIstatus.append(status)\n",
    "    \n",
    "\n",
    "phenotype_tmp['BMI_status'] = np.array(BMIstatus)\n",
    "phenotype_tmp['BMI_sds'] = np.array(BMIsds) \n",
    "phenotype_tmp = phenotype_tmp.drop(['age', 'sex', 'BMI'], axis=1)\n",
    "phenotype_final = pd.merge(phenotype, phenotype_tmp, how='left', left_on='subjectkey', right_on='subjectkey')\n",
    "phenotype_final = phenotype_final.loc[(phenotype_final['BMI_sds'] < 5) & (phenotype_final['BMI_sds'] > -5)]\n",
    "phenotype_final.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 year follow up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_params(subj_age:float, Ref_Chart: pd.DataFrame): \n",
    "    for i in range(len(Ref_Chart) - 1): \n",
    "        start = Ref_Chart['agemos'][i]\n",
    "        end = Ref_Chart['agemos'][i+1]\n",
    "        if subj_age >= start and subj_age < end: \n",
    "            if subj_age <= start + 0.5: \n",
    "                reference_params = Ref_Chart.iloc[i]\n",
    "            elif subj_age > start + 0.5: \n",
    "                reference_params = Ref_Chart.iloc[i+1]\n",
    "        else: \n",
    "            pass \n",
    "    return reference_params  \n",
    "\n",
    "\n",
    "def sds_calculator(BMI, L, M, S): \n",
    "    numerator = (BMI / M) ** L -1   # 분자 \n",
    "    denominator = L * S     # 분모\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "\n",
    "def calculating_subj_BMIsds(subj: pd.Series, Ref_Chart: pd.DataFrame) -> float: \n",
    "    age = subj['age_1year']\n",
    "    BMI = subj['BMI_1year']\n",
    "    sex = subj['sex']\n",
    "    sex_Ref_Chart = Ref_Chart[Ref_Chart['sex'] == sex].reset_index(drop=True)\n",
    "    reference_params = get_reference_params(subj_age=age, Ref_Chart=sex_Ref_Chart)\n",
    "    subj_BMIsds = sds_calculator(BMI=BMI, L=reference_params['L'], M=reference_params[\"M\"], S=reference_params[\"S\"])\n",
    "\n",
    "    P5 = reference_params['P5']\n",
    "    P85 = reference_params['P85']\n",
    "\n",
    "    if BMI <= P5: \n",
    "        status = \"underweight\"\n",
    "    elif BMI > P5 and BMI < P85: \n",
    "        status = \"normal\"\n",
    "    elif BMI >= P85: \n",
    "        status = \"overweight\"\n",
    "    return subj_BMIsds, status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10792/10792 [00:15<00:00, 675.51it/s]\n"
     ]
    }
   ],
   "source": [
    "Ref_Chart_dir = '/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/bmi-age-2022.csv'\n",
    "Ref_Chart = pd.read_csv(Ref_Chart_dir)\n",
    "\n",
    "phenotype = pd.read_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total.csv')\n",
    "phenotype_tmp = phenotype[['subjectkey','age', 'sex', 'weight','BMI','BMI_sds', 'BMI_status']] \n",
    "phenotype_tmp = phenotype_tmp.dropna(axis=0)\n",
    "phenotype_tmp.rename(columns={'BMI':'BMI_baseline', 'BMI_sds':'BMI_sds_baseline', 'BMI_status': 'BMI_status_baseline', 'weight':'weight_baseline'}, inplace=True)\n",
    "\n",
    "phenotype1 = pd.read_csv(\"/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD Release4.0 Tabular dataset.csv\")\n",
    "phenotype1 = phenotype1[phenotype1['eventname'] == \"1_year_follow_up_y_arm_1\"]\n",
    "phenotype1 = phenotype1.drop(['eventname','sex'], axis=1)\n",
    "phenotype1.rename(columns={'bmi':'BMI_1year', 'weight':'weight_1year'}, inplace=True)\n",
    "phenotype1 = phenotype1.reset_index(drop=True)\n",
    "for i in range(len(phenotype1['subjectkey'].values)):\n",
    "    phenotype1['subjectkey'].values[i] = phenotype1['subjectkey'].values[i].replace('_','')\n",
    "\n",
    "phenotype1_tmp = phenotype1[['subjectkey', 'BMI_1year', 'weight_1year']]\n",
    "phenotype1_tmp = phenotype1_tmp.dropna(axis=0)\n",
    "phenotype1_tmp = pd.merge(phenotype_tmp, phenotype1_tmp, how='inner', on='subjectkey' )\n",
    "# add 12 months to baseline age\n",
    "phenotype1_tmp['age_1year'] = phenotype1_tmp['age'].values + 12 \n",
    "\n",
    "# calculating BMI sds of each subject\n",
    "BMIsds = []\n",
    "BMIstatus = [] \n",
    "\n",
    "for i in tqdm(range(len(phenotype1_tmp))): \n",
    "    subj_BMIsds, status = calculating_subj_BMIsds(subj = phenotype1_tmp.iloc[i], Ref_Chart=Ref_Chart)\n",
    "    BMIsds.append(subj_BMIsds)\n",
    "    BMIstatus.append(status)\n",
    "    \n",
    "\n",
    "phenotype1_tmp['BMI_status_1year'] = np.array(BMIstatus)\n",
    "phenotype1_tmp['BMI_sds_1year'] = np.array(BMIsds) \n",
    "phenotype1_tmp['BMI_sds_change'] = phenotype1_tmp['BMI_sds_1year'].values - phenotype1_tmp['BMI_sds_baseline'].values\n",
    "phenotype1_tmp['BMI_change'] = phenotype1_tmp['BMI_1year'].values - phenotype1_tmp['BMI_baseline'].values\n",
    "phenotype1_tmp['weight_change'] = phenotype1_tmp['weight_1year'].values - phenotype1_tmp['weight_baseline'].values\n",
    "phenotype1_tmp = phenotype1_tmp.drop(['age', 'age_1year','sex', 'BMI_1year'], axis=1)\n",
    "phenotype1_final = pd.merge(phenotype1, phenotype1_tmp, how='left', left_on='subjectkey', right_on='subjectkey')\n",
    "phenotype1_final = phenotype1_final.loc[(phenotype1_final['BMI_sds_1year'] < 5) & (phenotype1_final['BMI_sds_1year'] > -5)]\n",
    "phenotype1_final.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total_1years_revised.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_template = np.zeros(len(phenotype1_final))\n",
    "for i in range(len(phenotype1_final)): \n",
    "    difference = phenotype1_final['BMI_sds_change'].values[i]\n",
    "    if difference >= 0.2 :\n",
    "        gain_template[i] = 1\n",
    "    elif  difference < 0.2 and difference > -0.2:\n",
    "        pass\n",
    "    elif difference <= - 0.2 : \n",
    "        gain_template[i] = np.nan\n",
    "\n",
    "\n",
    "loss_template = np.zeros(len(phenotype1_final))\n",
    "for i in range(len(phenotype1_final)): \n",
    "    difference = phenotype1_final['BMI_sds_change'].values[i]\n",
    "    if difference >= 0.2 :\n",
    "        loss_template[i] = np.nan\n",
    "    elif  difference < 0.2 and difference > -0.2:\n",
    "        pass\n",
    "    elif difference <= - 0.2 : \n",
    "        loss_template[i] = 1\n",
    "\n",
    "\n",
    "phenotype1_final['BMI_gain'] = gain_template\n",
    "phenotype1_final['BMI_loss'] = loss_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_gain = phenotype1_final.dropna(axis=0, subset=['BMI_gain'], inplace=False)\n",
    "phenotype_gain = phenotype_gain.drop(['BMI_loss'], axis=1)\n",
    "phenotype_gain =phenotype_gain.reset_index(drop=True)\n",
    "phenotype_gain.to_csv(\"/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total_1years_revised_BMIgain.csv\", index=False)\n",
    "\n",
    "phenotype_loss = phenotype1_final.dropna(axis=0, subset=['BMI_loss'], inplace=False)\n",
    "phenotype_loss = phenotype_loss.drop(['BMI_gain'], axis=1)\n",
    "phenotype_loss =phenotype_loss.reset_index(drop=True)\n",
    "phenotype_loss.to_csv(\"/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total_1years_revised_BMIloss.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2194210275.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abnormal_normal['become_normal'] = np.array([1 for x in range(len(abnormal_normal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2194210275.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_abnormal['become_overweight'] = np.array([1 for x in range(len(normal_abnormal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2194210275.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_normal['become_overweight'] = np.array([0 for x in range(len(normal_normal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2194210275.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_normal['become_normal'] = np.array([0 for x in range(len(normal_normal))])\n"
     ]
    }
   ],
   "source": [
    "# (baseline) abnormal to (1 year) normal acceleration \n",
    "abnormal_normal = phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'underweight') & (phenotype_gain['BMI_status_1year'] == 'normal') & (phenotype_gain['BMI_gain'] == 1)]\n",
    "abnormal_normal['become_normal'] = np.array([1 for x in range(len(abnormal_normal))])\n",
    "# (baseline) normal to (1 year) abnormal acceleration \n",
    "normal_abnormal = phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'normal') & (phenotype_gain['BMI_status_1year'] == 'overweight') & (phenotype_gain['BMI_gain'] == 1)]\n",
    "normal_abnormal['become_overweight'] = np.array([1 for x in range(len(normal_abnormal))])\n",
    "# normal to normal \n",
    "normal_normal = phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'normal') & (phenotype_gain['BMI_status_1year'] == 'normal') & (phenotype_gain['BMI_gain'] == 0)]\n",
    "normal_normal['become_overweight'] = np.array([0 for x in range(len(normal_normal))])\n",
    "normal_normal['become_normal'] = np.array([0 for x in range(len(normal_normal))])\n",
    "\n",
    "underweight = pd.concat([abnormal_normal, normal_normal])\n",
    "underweight = underweight.reset_index(drop=True)\n",
    "underweight = underweight[['subjectkey', 'become_normal']]\n",
    "overweight = pd.concat([normal_abnormal, normal_normal])\n",
    "overweight = overweight.reset_index(drop=True) \n",
    "overweight = overweight[['subjectkey', 'become_overweight']]\n",
    "\n",
    "new_df_gain = pd.merge(phenotype_gain, overweight, how='left', left_on='subjectkey', right_on='subjectkey') \n",
    "new_df_gain = pd.merge(new_df_gain, underweight, how='left', left_on='subjectkey', right_on='subjectkey') \n",
    "new_df_gain.to_csv(\"/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total_1years_revised_BMIgain.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/376323555.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abnormal_normal['become_normal'] = np.array([1 for x in range(len(abnormal_normal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/376323555.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_abnormal['become_underweight'] = np.array([1 for x in range(len(normal_abnormal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/376323555.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_normal['become_normal'] = np.array([0 for x in range(len(normal_normal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/376323555.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_normal['become_underweight'] = np.array([0 for x in range(len(normal_normal))])\n"
     ]
    }
   ],
   "source": [
    "# (baseline) abnormal to (1 year) normal \n",
    "abnormal_normal = phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'overweight') & (phenotype_loss['BMI_status_1year'] == 'normal') & (phenotype_loss['BMI_loss'] == 1)]\n",
    "abnormal_normal['become_normal'] = np.array([1 for x in range(len(abnormal_normal))])\n",
    "# (baseline) normal to (1 year) abnormal \n",
    "normal_abnormal = phenotype_loss.loc[(phenotype_gain['BMI_status_baseline'] == 'normal') & (phenotype_gain['BMI_status_1year'] ==  'underweight') & (phenotype_loss['BMI_loss'] == 1)]\n",
    "normal_abnormal['become_underweight'] = np.array([1 for x in range(len(normal_abnormal))])\n",
    "\n",
    "# normal to normal \n",
    "normal_normal = phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'normal') & (phenotype_loss['BMI_status_1year'] == 'normal') & (phenotype_loss['BMI_loss'] == 0)]\n",
    "normal_normal['become_normal'] = np.array([0 for x in range(len(normal_normal))])\n",
    "normal_normal['become_underweight'] = np.array([0 for x in range(len(normal_normal))])\n",
    "\n",
    "\n",
    "overweight = pd.concat([abnormal_normal, normal_normal])\n",
    "overweight = overweight.reset_index(drop=True)\n",
    "overweight = overweight[['subjectkey', 'become_normal']]\n",
    "underweight = pd.concat([normal_abnormal, normal_normal])\n",
    "underweight = underweight.reset_index(drop=True)\n",
    "underweight = underweight[['subjectkey', 'become_underweight']]\n",
    "\n",
    "\n",
    "new_df_loss = pd.merge(phenotype_loss, overweight, how='left', left_on='subjectkey', right_on='subjectkey') \n",
    "new_df_loss = pd.merge(new_df_loss, underweight, how='left', left_on='subjectkey', right_on='subjectkey') \n",
    "new_df_loss.to_csv(\"/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total_1years_revised_BMIloss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For pretraining with BMI and transfer learning to BMI change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratification with propensity score \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from psmpy import PsmPy\n",
    "from psmpy.functions import cohenD\n",
    "\n",
    "def partition_stratified_train_test(input_df, target, cat_cov:list, num_cov: list,train_size=0.7, val_size=0.1, test_size=0.2, n_percentile=5,n_partition=4,seed=1234):\n",
    "    def concat_df(df, subject_key): \n",
    "        df_concatenated = pd.DataFrame()\n",
    "        for subj in subject_key: \n",
    "            tmp = df[df['subjectkey'] == subj]\n",
    "            df_concatenated = pd.concat([df_concatenated, tmp])\n",
    "            \n",
    "        return df_concatenated\n",
    "\n",
    "    \"\"\"\n",
    "    propensity score stratification ref: https://towardsdatascience.com/psmpy-propensity-score-matching-in-python-a3e0cd4d2631\n",
    "    \n",
    "    1) calculae propensity score there by stratify 5 percentile and assign rank \n",
    "    2) stratified split train and test data \n",
    "    3) stratified split train data to train and validation data \n",
    "    4) stratified sampling control data for train, validation and test \n",
    "    ##TODO##\n",
    "    + if subjects who have NaN values in covariates used for calculating propensity scores are assigned to only train set \n",
    "\n",
    "    n_partition=5\n",
    "    train_size = 0.8 \n",
    "    val_size = 0.125\n",
    "    test_size = 0.2 \n",
    "    >>> This is the same as split the whole dataset into train/validation/test with ratio of 0.7/0.1/0.2\n",
    "\n",
    "    n_partition=4\n",
    "    train_size = 0.65\n",
    "    test_size =0.25 \n",
    "    val_size = 0.13 (parameter for train_test_split)\n",
    "    >>> This is the same as split the whole dataset into train/validation/test with ratio of 0.65/0.1/0.25\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_partition,random_state=seed, shuffle=True)\n",
    "    q = np.linspace(0, 1, n_percentile+1)\n",
    "    labels = np.linspace(0, n_percentile-1, n_percentile)\n",
    "\n",
    "    # one hot labeling categorical values \n",
    "    #ps_df = input_df[['subjectkey', target, 'BMI_sds_change'] + cat_cov + num_cov].copy() \n",
    "    ps_df = input_df[['subjectkey', target, 'BMI_sds_baseline'] + cat_cov + num_cov].copy() \n",
    "    ps_df_tmp = ps_df.dropna(axis=0).reset_index(drop=True)\n",
    "    ps_df_cat_cov = pd.get_dummies(ps_df_tmp[cat_cov].astype('category'))\n",
    "    ps_df_tmp = ps_df_tmp.drop(columns=cat_cov, axis=1)\n",
    "    ps_df_tmp = pd.concat([ps_df_tmp, ps_df_cat_cov], axis=1)\n",
    "    \n",
    "\n",
    "    # PS calculation \n",
    "    psm = PsmPy(ps_df_tmp, treatment=target, indx='subjectkey')\n",
    "    psm.logistic_ps(balance=True)\n",
    "    ps_df_tmp = psm.predicted_data[['subjectkey','propensity_score']]\n",
    "\n",
    "    # stratify 4 percentile (test_size = 0.25)\n",
    "    percentile_class, _ = pd.qcut(ps_df_tmp['propensity_score'].values, q, labels=labels, retbins=True)\n",
    "    ps_df_tmp['percentile'] = percentile_class\n",
    "    ps_df_tmp = ps_df_tmp[['subjectkey', 'percentile']]\n",
    "    \n",
    "    \n",
    "    # separate case/control\n",
    "    case = input_df[input_df[target] == 1].reset_index(drop=True)\n",
    "    case = pd.merge(case, ps_df_tmp, how='inner', on='subjectkey')\n",
    "    control = input_df[input_df[target] == 0].reset_index(drop=True)\n",
    "    control = pd.merge(control, ps_df_tmp, how='inner', on='subjectkey')\n",
    "    num_total_case = len(case)\n",
    "    num_total_train = len(control)\n",
    "    \n",
    "\n",
    "    # stratify 10 percentile (test_size = 0.1)\n",
    "    #percentile_class, _ = pd.qcut(case['BMI_sds_change'].values, q, labels=labels, retbins=True)\n",
    "    #case['percentile'] = percentile_class\n",
    "\n",
    "    partition_result = {}\n",
    "    for i, (train_val_idx, test_idx) in enumerate(skf.split(case['subjectkey'], case['percentile'])):\n",
    "    #for i, (train_val_idx, test_idx) in enumerate(skf.split(case['subjectkey'], case['abcd.site'])):\n",
    "        # assign samples knocked out by nan filtering for propensity scores to train set.\n",
    "        case_add = input_df[['subjectkey', target, 'BMI_sds_change'] + cat_cov + num_cov].copy() \n",
    "        case_add = case_add[case_add.isna().any(axis=1)]\n",
    "        case_add = case_add[case_add[target] == 1]\n",
    "        case_add = case_add[['subjectkey']]\n",
    "        case_add['partition%s' % i] = ['train' for _ in range(len(case_add))]\n",
    "\n",
    "        # split train/test\n",
    "        case_test = case.loc[test_idx]\n",
    "        case_train_val = case.loc[train_val_idx].reset_index(drop=True)\n",
    "        control_test = control.groupby('percentile', group_keys=False).apply(lambda x: x.sample(frac=len(case_test)/len(control), random_state=seed))   # stratified random sampling, where len(case_test) == len(control_test) \n",
    "        control_test_removed = control.drop(axis=0, index=control_test.index).reset_index(drop=True)\n",
    "        control_train_val = control_test_removed.groupby('percentile', group_keys=False).apply(lambda x: x.sample(frac=(len(case_train_val)+len(case_add))/len(control_test_removed), random_state=seed))\n",
    "        #control_train_val = control_test_removed.groupby('percentile', group_keys=False).apply(lambda x: x.sample(frac=len(case_train_val)/len(control_test_removed)))\n",
    "        \n",
    "        \n",
    "        # split train into train/val\n",
    "        subjectkey_case_train_val, percentile_case_train_val = case_train_val['subjectkey'].values, case_train_val['percentile'].values\n",
    "        subjectkey_case_train, subjectkey_case_val, _, _ = train_test_split(subjectkey_case_train_val, percentile_case_train_val, test_size=0.125, shuffle=True, random_state=seed+1, stratify=percentile_case_train_val)\n",
    "        #subjectkey_case_train, subjectkey_case_val, _, _ = train_test_split(subjectkey_case_train_val, percentile_case_train_val, test_size=0.13,random_state=seed+1, shuffle=True, stratify=percentile_case_train_val)\n",
    "        case_val = concat_df(case_train_val, subjectkey_case_val)\n",
    "        case_train = concat_df(case_train_val, subjectkey_case_train)\n",
    "\n",
    "        \n",
    "        # stratified sampling control of train/val\n",
    "        control_val = control_train_val.groupby('percentile', group_keys=False).apply(lambda x: x.sample(frac=len(case_val)/len(control_train_val), random_state=seed))\n",
    "        control_train = control_train_val.drop(axis=0, index=control_val.index).reset_index(drop=True)\n",
    "        #control_train = pd.concat([control_train.drop(columns='percentile'), nan_train], axis=0)\n",
    "        \n",
    "\n",
    "        \n",
    "        case_test['partition%s' % i] = ['test' for _ in range(len(case_test))]\n",
    "        case_val['partition%s' % i] = ['val' for _ in range(len(case_val))]\n",
    "        case_train['partition%s' % i] = ['train' for _ in range(len(case_train))]\n",
    "        control_test['partition%s' % i] = ['test' for _ in range(len(control_test))]\n",
    "        control_val['partition%s' % i] = ['val' for _ in range(len(control_val))]\n",
    "        control_train['partition%s' % i] = ['train' for _ in range(len(control_train))]\n",
    "\n",
    "        partition_df = pd.concat([case_train, control_train, case_val, control_val, case_test, control_test])\n",
    "        partition_df = partition_df[['subjectkey', 'partition%s' % i]]\n",
    "        partition_df = pd.concat([partition_df, case_add], axis=0)\n",
    "        \n",
    "        partition_result['partition%s' % i] = partition_df\n",
    "\n",
    "    final_df = input_df.drop(columns=cat_cov + num_cov).copy()\n",
    "    for i in range(n_partition):\n",
    "        final_df = pd.merge(final_df, partition_result['partition%s' % i], how='left', on='subjectkey')\n",
    "\n",
    "    return final_df\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def partition_train_test_baseline(baseline_data, longitudinal_data,  train_size=0.75, val_size=0.05, test_size=0.2, n_partition=4, seed=1234): \n",
    "    baseline_data_tmp = baseline_data[['subjectkey','BMI_baseline', 'BMI_sds_baseline']]\n",
    "    baseline_data_tmp = baseline_data_tmp.dropna(axis=0)\n",
    "\n",
    "    num_total = len(baseline_data)\n",
    "    num_train = int(num_total * train_size)\n",
    "    num_test = int(num_total * test_size)\n",
    "    num_val  = num_total - num_train - num_test\n",
    "\n",
    "    phenotype_partition_final = {}\n",
    "    for i in range(n_partition): \n",
    "        longitudinal_data_tmp = longitudinal_data[['subjectkey', 'partition%s' % i ]]\n",
    "        phenotype_partition = pd.merge(baseline_data_tmp, longitudinal_data_tmp, how='left', left_on='subjectkey', right_on='subjectkey')\n",
    "        phenotype_partition = phenotype_partition.drop(['BMI_baseline', 'BMI_sds_baseline'], axis=1)\n",
    "        test_1y = phenotype_partition[phenotype_partition['partition%s' % i] == 'test']\n",
    "        val_1y = phenotype_partition[phenotype_partition['partition%s' % i] == 'val']\n",
    "        train_1y = phenotype_partition[phenotype_partition['partition%s' % i] == 'train']\n",
    "\n",
    "        num_test_tmp = num_test - len(test_1y)\n",
    "        num_val_tmp = num_val - len(val_1y)\n",
    "        num_train_tmp = num_train - len(train_1y)\n",
    "\n",
    "        phenotype_partition_all = phenotype_partition.drop(index=test_1y.index, axis=0).drop(index=val_1y.index, axis=0).drop(index=train_1y.index, axis=0)\n",
    "        #phenotype_partition_all = phenotype_partition_all.sample(frac=1, random_state=seed).reset_index(drop=True)  # shuffling하고 index reset\n",
    "\n",
    "        phenotype_partition_train = phenotype_partition_all.iloc[:num_train_tmp]\n",
    "        phenotype_partition_test = phenotype_partition_all.iloc[num_train_tmp:num_train_tmp+num_test_tmp]\n",
    "        phenotype_partition_val = phenotype_partition_all.iloc[num_train_tmp+num_test_tmp:]\n",
    "\n",
    "\n",
    "        phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
    "        phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
    "        phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
    "        \n",
    "        phenotype_partition_final_tmp = pd.concat([phenotype_partition_train, train_1y, phenotype_partition_val, val_1y, phenotype_partition_test, test_1y])\n",
    "        phenotype_partition_final['partition%s' % i] = phenotype_partition_final_tmp\n",
    "        \n",
    "\n",
    "    partitioned_data_baseline = baseline_data\n",
    "    for i in range(n_partition): \n",
    "        partitioned_data_baseline = pd.merge(partitioned_data_baseline, phenotype_partition_final['partition%s' % i], how='left', left_on='subjectkey', right_on='subjectkey')\n",
    "\n",
    "    return partitioned_data_baseline\n",
    "\n",
    "\n",
    "\n",
    "def check_partition(input_df, target='become_overweight', split='train', n_percentile=5, n_partition=4): \n",
    "    q = np.linspace(0, 1, n_percentile+1)\n",
    "    labels = np.linspace(0, n_percentile-1, n_percentile)\n",
    "\n",
    "    # separate case/control\n",
    "    case = input_df[input_df[target] == 1].reset_index(drop=True)\n",
    "    control = input_df[input_df[target] == 0].reset_index(drop=True)\n",
    "    num_total_case = len(case)\n",
    "    num_total_train = len(control)\n",
    "\n",
    "    # stratify 10 percentile (test_size = 0.1)\n",
    "    percentile_class, _ = pd.qcut(case['BMI_sds_change'].values, q, labels=labels, retbins=True)\n",
    "    case['percentile'] = percentile_class\n",
    "\n",
    "    check = pd.merge(input_df, case[['subjectkey', 'percentile']], how='inner', on='subjectkey')\n",
    "\n",
    "    for i in range(n_partition): \n",
    "        tmp = check[check['partition%s' % i] == split]\n",
    "        print(\"In partition{}, {} have following counts for each percentile: {}\".format(i, split, tmp['percentile'].value_counts().values.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ps_df_tmp['percentile'] = percentile_class\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In partition0, train have following counts for each percentile: [49, 45, 45, 43, 43, 42, 42, 41, 39, 39]\n",
      "In partition1, train have following counts for each percentile: [52, 47, 46, 45, 43, 42, 41, 38, 38, 36]\n",
      "In partition2, train have following counts for each percentile: [45, 44, 44, 43, 43, 43, 42, 42, 41, 41]\n",
      "In partition3, train have following counts for each percentile: [47, 45, 44, 44, 43, 42, 42, 42, 40, 39]\n",
      "In partition4, train have following counts for each percentile: [47, 47, 45, 44, 43, 43, 43, 41, 39, 36]\n"
     ]
    }
   ],
   "source": [
    "cat_cov = ['sex', 'abcd.site', 'race.ethnicity', 'married'] \n",
    "num_cov = ['age', 'high.educ', 'income'] \n",
    "phenotype = pd.read_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total.csv')\n",
    "phenotype_tmp = phenotype.rename(columns={'BMI_sds': 'BMI_sds_baseline', 'BMI': 'BMI_baseline'})\n",
    "new_df_gain_tmp = new_df_gain.drop(columns=['age', 'income'])   # remove duplicated columns\n",
    "new_df_gain_tmp = pd.merge(new_df_gain_tmp, phenotype_tmp[['subjectkey'] + cat_cov + num_cov], how='inner', on='subjectkey')\n",
    "partitioned_data_1yafter = partition_stratified_train_test(new_df_gain_tmp, 'become_overweight', cat_cov=cat_cov, num_cov=num_cov, n_percentile=10, n_partition=5, seed=1234)\n",
    "partitioned_data_baseline = partition_train_test_baseline(baseline_data=phenotype_tmp , longitudinal_data=partitioned_data_1yafter, n_partition=5, seed=1234)\n",
    "partitioned_data_1yafter.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_1years_become_overweight_10PS_stratified_partitioned_5fold.csv', index=False)\n",
    "partitioned_data_baseline.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_for_pretraining_1y_after_become_overweight_10PS_stratified_5fold.csv', index=False)\n",
    "\n",
    "check_partition(partitioned_data_1yafter, target='become_overweight', split='train', n_percentile=10, n_partition=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ps_df_tmp['percentile'] = percentile_class\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/2507061846.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In partition0, train have following counts for each percentile: [14, 14, 14, 13, 13, 12, 10, 9, 9, 9]\n",
      "In partition1, train have following counts for each percentile: [15, 14, 14, 13, 12, 12, 11, 10, 9, 7]\n",
      "In partition2, train have following counts for each percentile: [14, 13, 13, 13, 12, 12, 11, 10, 10, 9]\n",
      "In partition3, train have following counts for each percentile: [15, 14, 12, 12, 12, 12, 11, 10, 10, 10]\n",
      "In partition4, train have following counts for each percentile: [15, 14, 14, 13, 12, 12, 11, 10, 9, 8]\n"
     ]
    }
   ],
   "source": [
    "cat_cov = ['sex', 'abcd.site', 'race.ethnicity'] \n",
    "num_cov = ['age', 'high.educ', 'income'] \n",
    "phenotype = pd.read_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total.csv')\n",
    "phenotype_tmp = phenotype.rename(columns={'BMI_sds': 'BMI_sds_baseline', 'BMI': 'BMI_baseline'})\n",
    "new_df_gain_tmp = new_df_gain.drop(columns=['age', 'income'])   # remove duplicated columns\n",
    "new_df_gain_tmp = pd.merge(new_df_gain_tmp, phenotype_tmp[['subjectkey'] + cat_cov + num_cov], how='inner', on='subjectkey')\n",
    "partitioned_data_1yafter = partition_stratified_train_test(new_df_gain_tmp, 'become_normal', cat_cov=cat_cov, num_cov=num_cov, n_percentile=10, n_partition=5, seed=1234)\n",
    "partitioned_data_baseline = partition_train_test_baseline(baseline_data=phenotype_tmp , longitudinal_data=partitioned_data_1yafter, n_partition=5, seed=1234)\n",
    "partitioned_data_1yafter.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_1years_become_normal_10PS_stratified_partitioned_5fold.csv', index=False)\n",
    "partitioned_data_baseline.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_for_pretraining_1y_after_become_normal_10PS_stratified_5fold.csv', index=False)\n",
    "\n",
    "check_partition(partitioned_data_1yafter, target='become_normal', split='train', n_percentile=10, n_partition=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['become_underweight'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m new_df_gain_tmp \u001b[38;5;241m=\u001b[39m new_df_gain\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m'\u001b[39m])   \u001b[38;5;66;03m# remove duplicated columns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m new_df_gain_tmp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(new_df_gain_tmp, phenotype_tmp[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubjectkey\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m cat_cov \u001b[38;5;241m+\u001b[39m num_cov], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubjectkey\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m partitioned_data_1yafter \u001b[38;5;241m=\u001b[39m \u001b[43mpartition_stratified_train_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_df_gain_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbecome_underweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_cov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_cov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_percentile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_partition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1234\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m partitioned_data_baseline \u001b[38;5;241m=\u001b[39m partition_train_test_baseline(baseline_data\u001b[38;5;241m=\u001b[39mphenotype_tmp , longitudinal_data\u001b[38;5;241m=\u001b[39mpartitioned_data_1yafter, n_partition\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234\u001b[39m)\n\u001b[1;32m      9\u001b[0m partitioned_data_1yafter\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_1years_become_underweight_10PS_stratified_partitioned_5fold.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[14], line 47\u001b[0m, in \u001b[0;36mpartition_stratified_train_test\u001b[0;34m(input_df, target, cat_cov, num_cov, train_size, val_size, test_size, n_percentile, n_partition, seed)\u001b[0m\n\u001b[1;32m     43\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, n_percentile\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_percentile)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# one hot labeling categorical values \u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#ps_df = input_df[['subjectkey', target, 'BMI_sds_change'] + cat_cov + num_cov].copy() \u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m ps_df \u001b[38;5;241m=\u001b[39m \u001b[43minput_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubjectkey\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBMI_sds_baseline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcat_cov\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_cov\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy() \n\u001b[1;32m     48\u001b[0m ps_df_tmp \u001b[38;5;241m=\u001b[39m ps_df\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m ps_df_cat_cov \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(ps_df_tmp[cat_cov]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3810'>3811</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3811'>3812</a>\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3812'>3813</a>\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3814'>3815</a>\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3815'>3816</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6066'>6067</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6067'>6068</a>\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6069'>6070</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6071'>6072</a>\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6072'>6073</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6073'>6074</a>\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6129'>6130</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6131'>6132</a>\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6132'>6133</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['become_underweight'] not in index\""
     ]
    }
   ],
   "source": [
    "cat_cov = ['sex', 'abcd.site', 'race.ethnicity'] \n",
    "num_cov = ['age', 'high.educ', 'income'] \n",
    "phenotype = pd.read_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total.csv')\n",
    "phenotype_tmp = phenotype.rename(columns={'BMI_sds': 'BMI_sds_baseline', 'BMI': 'BMI_baseline'})\n",
    "new_df_gain_tmp = new_df_gain.drop(columns=['age', 'income'])   # remove duplicated columns\n",
    "new_df_gain_tmp = pd.merge(new_df_gain_tmp, phenotype_tmp[['subjectkey'] + cat_cov + num_cov], how='inner', on='subjectkey')\n",
    "partitioned_data_1yafter = partition_stratified_train_test(new_df_gain_tmp, 'become_underweight', cat_cov=cat_cov, num_cov=num_cov, n_percentile=10, n_partition=5, seed=1234)\n",
    "partitioned_data_baseline = partition_train_test_baseline(baseline_data=phenotype_tmp , longitudinal_data=partitioned_data_1yafter, n_partition=5, seed=1234)\n",
    "partitioned_data_1yafter.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_1years_become_underweight_10PS_stratified_partitioned_5fold.csv', index=False)\n",
    "partitioned_data_baseline.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_for_pretraining_1y_after_become_underweight_10PS_stratified_5fold.csv', index=False)\n",
    "\n",
    "check_partition(partitioned_data_1yafter, target='become_underweight', split='train', n_percentile=10, n_partition=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "underweight -> underweight: 88\n",
      "underweight -> normal: 162\n",
      "normal -> normal: 2538\n",
      "normal -> overweight: 592\n",
      "overweight -> overweight: 1995\n",
      "underweight -> overweight: 6\n"
     ]
    }
   ],
   "source": [
    "num_underweight_underweight = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'underweight') & (phenotype_gain['BMI_status_1year'] == 'underweight') & (phenotype_gain['BMI_gain'] == 0)]) \n",
    "num_underweight_normal = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'underweight') & (phenotype_gain['BMI_status_1year'] == 'normal') & (phenotype_gain['BMI_gain'] == 1)]) \n",
    "num_normal_normal = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'normal') & (phenotype_gain['BMI_status_1year'] == 'normal') & (phenotype_gain['BMI_gain'] == 0)]) \n",
    "num_normal_overweight = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'normal') & (phenotype_gain['BMI_status_1year'] == 'overweight') & (phenotype_gain['BMI_gain'] == 1)]) \n",
    "num_overweight_overweight = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'overweight') & (phenotype_gain['BMI_status_1year'] == 'overweight') & (phenotype_gain['BMI_gain'] == 0)])\n",
    "num_underweight_overweight = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'underweight') & (phenotype_gain['BMI_status_1year'] == 'overweight') & (phenotype_gain['BMI_gain'] == 1)])\n",
    "\n",
    "print(\"underweight -> underweight: {}\".format(num_underweight_underweight))\n",
    "print(\"underweight -> normal: {}\".format(num_underweight_normal))\n",
    "print(\"normal -> normal: {}\".format(num_normal_normal))\n",
    "print(\"normal -> overweight: {}\".format(num_normal_overweight))\n",
    "print(\"overweight -> overweight: {}\".format(num_overweight_overweight))\n",
    "print(\"underweight -> overweight: {}\".format(num_underweight_overweight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overweight -> overweight: 1995\n",
      "overweight -> normal: 353\n",
      "overweight -> underweight: 1\n",
      "normal -> normal: 2538\n",
      "normal -> underweight: 163\n",
      "underweight -> underweight: 88\n"
     ]
    }
   ],
   "source": [
    "num_overweight_overweight = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'overweight') & (phenotype_loss['BMI_status_1year'] == 'overweight') & (phenotype_loss['BMI_loss'] == 0)])\n",
    "num_overweight_normal = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'overweight') & (phenotype_loss['BMI_status_1year'] == 'normal') & (phenotype_loss['BMI_loss'] == 1)])\n",
    "num_overweight_underweight = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'overweight') & (phenotype_loss['BMI_status_1year'] == 'underweight') & (phenotype_loss['BMI_loss'] == 1)])\n",
    "num_normal_normal = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'normal') & (phenotype_loss['BMI_status_1year'] == 'normal') & (phenotype_loss['BMI_loss'] == 0)]) \n",
    "num_normal_underweight = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'normal') & (phenotype_loss['BMI_status_1year'] == 'underweight') & (phenotype_loss['BMI_loss'] == 1)]) \n",
    "num_underweight_underweight = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'underweight') & (phenotype_loss['BMI_status_1year'] == 'underweight') & (phenotype_loss['BMI_loss'] == 0)]) \n",
    "\n",
    "\n",
    "print(\"overweight -> overweight: {}\".format(num_overweight_overweight))\n",
    "print(\"overweight -> normal: {}\".format(num_overweight_normal))\n",
    "print(\"overweight -> underweight: {}\".format(num_overweight_underweight))\n",
    "print(\"normal -> normal: {}\".format(num_normal_normal))\n",
    "print(\"normal -> underweight: {}\".format(num_normal_underweight))\n",
    "print(\"underweight -> underweight: {}\".format(num_underweight_underweight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = phenotype[['subjectkey', 'sex']]\n",
    "phenotype_gain_sex = pd.merge(phenotype_gain, sex, on='subjectkey', how='inner')\n",
    "phenotype_loss_sex = pd.merge(phenotype_loss, sex, on='subjectkey', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "underweight -> underweight: 33\n",
      "underweight -> normal: 91\n",
      "normal -> normal: 1304\n",
      "normal -> overweight: 335\n",
      "overweight -> overweight: 1075\n",
      "underweight -> overweight: 6\n"
     ]
    }
   ],
   "source": [
    "num_underweight_underweight = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'underweight') & (phenotype_gain_sex['BMI_status_1year'] == 'underweight') & (phenotype_gain_sex['BMI_gain'] == 0) & (phenotype_gain_sex['sex'] == 1)]) \n",
    "num_underweight_normal = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'underweight') & (phenotype_gain_sex['BMI_status_1year'] == 'normal') & (phenotype_gain_sex['BMI_gain'] == 1) & (phenotype_gain_sex['sex'] == 1)]) \n",
    "num_normal_normal = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'normal') & (phenotype_gain_sex['BMI_status_1year'] == 'normal') & (phenotype_gain_sex['BMI_gain'] == 0) & (phenotype_gain_sex['sex'] == 1)]) \n",
    "num_normal_overweight = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'normal') & (phenotype_gain_sex['BMI_status_1year'] == 'overweight') & (phenotype_gain_sex['BMI_gain'] == 1) & (phenotype_gain_sex['sex'] == 1)]) \n",
    "num_overweight_overweight = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'overweight') & (phenotype_gain_sex['BMI_status_1year'] == 'overweight') & (phenotype_gain_sex['BMI_gain'] == 0) & (phenotype_gain_sex['sex'] == 1)])\n",
    "num_underweight_overweight = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'underweight') & (phenotype_gain_sex['BMI_status_1year'] == 'overweight') & (phenotype_gain_sex['BMI_gain'] == 1) & (phenotype_gain_sex['sex'] == 1)])\n",
    "\n",
    "print(\"underweight -> underweight: {}\".format(num_underweight_underweight))\n",
    "print(\"underweight -> normal: {}\".format(num_underweight_normal))\n",
    "print(\"normal -> normal: {}\".format(num_normal_normal))\n",
    "print(\"normal -> overweight: {}\".format(num_normal_overweight))\n",
    "print(\"overweight -> overweight: {}\".format(num_overweight_overweight))\n",
    "print(\"underweight -> overweight: {}\".format(num_underweight_overweight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overweight -> overweight: 1075\n",
      "overweight -> normal: 197\n",
      "overweight -> underweight: 0\n",
      "normal -> normal: 1304\n",
      "normal -> underweight: 90\n",
      "underweight -> underweight: 33\n"
     ]
    }
   ],
   "source": [
    "num_overweight_overweight = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'overweight') & (phenotype_loss_sex['BMI_status_1year'] == 'overweight') & (phenotype_loss_sex['BMI_loss'] == 0) & (phenotype_loss_sex['sex'] == 1)])\n",
    "num_overweight_normal = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'overweight') & (phenotype_loss_sex['BMI_status_1year'] == 'normal') & (phenotype_loss_sex['BMI_loss'] == 1) & (phenotype_loss_sex['sex'] == 1)])\n",
    "num_overweight_underweight = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'overweight') & (phenotype_loss_sex['BMI_status_1year'] == 'underweight') & (phenotype_loss_sex['BMI_loss'] == 1) & (phenotype_loss_sex['sex'] == 1)])\n",
    "num_normal_normal = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'normal') & (phenotype_loss_sex['BMI_status_1year'] == 'normal') & (phenotype_loss_sex['BMI_loss'] == 0) & (phenotype_loss_sex['sex'] == 1)]) \n",
    "num_normal_underweight = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'normal') & (phenotype_loss_sex['BMI_status_1year'] == 'underweight') & (phenotype_loss_sex['BMI_loss'] == 1) & (phenotype_loss_sex['sex'] == 1)]) \n",
    "num_underweight_underweight = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'underweight') & (phenotype_loss_sex['BMI_status_1year'] == 'underweight') & (phenotype_loss_sex['BMI_loss'] == 0) & (phenotype_loss_sex['sex'] == 1)]) \n",
    "\n",
    "\n",
    "print(\"overweight -> overweight: {}\".format(num_overweight_overweight))\n",
    "print(\"overweight -> normal: {}\".format(num_overweight_normal))\n",
    "print(\"overweight -> underweight: {}\".format(num_overweight_underweight))\n",
    "print(\"normal -> normal: {}\".format(num_normal_normal))\n",
    "print(\"normal -> underweight: {}\".format(num_normal_underweight))\n",
    "print(\"underweight -> underweight: {}\".format(num_underweight_underweight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 year follow up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_params(subj_age:float, Ref_Chart: pd.DataFrame): \n",
    "    for i in range(len(Ref_Chart) - 1): \n",
    "        start = Ref_Chart['agemos'][i]\n",
    "        end = Ref_Chart['agemos'][i+1]\n",
    "        if subj_age >= start and subj_age < end: \n",
    "            if subj_age <= start + 0.5: \n",
    "                reference_params = Ref_Chart.iloc[i]\n",
    "            elif subj_age > start + 0.5: \n",
    "                reference_params = Ref_Chart.iloc[i+1]\n",
    "        else: \n",
    "            pass \n",
    "    return reference_params  \n",
    "\n",
    "\n",
    "def sds_calculator(BMI, L, M, S): \n",
    "    numerator = (BMI / M) ** L -1   # 분자 \n",
    "    denominator = L * S     # 분모\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "\n",
    "def calculating_subj_BMIsds(subj: pd.Series, Ref_Chart: pd.DataFrame) -> float: \n",
    "    age = subj['age_2year']\n",
    "    BMI = subj['BMI_2year']\n",
    "    sex = subj['sex']\n",
    "    sex_Ref_Chart = Ref_Chart[Ref_Chart['sex'] == sex].reset_index(drop=True)\n",
    "    reference_params = get_reference_params(subj_age=age, Ref_Chart=sex_Ref_Chart)\n",
    "    subj_BMIsds = sds_calculator(BMI=BMI, L=reference_params['L'], M=reference_params[\"M\"], S=reference_params[\"S\"])\n",
    "\n",
    "    P5 = reference_params['P5']\n",
    "    P85 = reference_params['P85']\n",
    "\n",
    "    if BMI <= P5: \n",
    "        status = \"underweight\"\n",
    "    elif BMI > P5 and BMI < P85: \n",
    "        status = \"normal\"\n",
    "    elif P95 > BMI >= P85: \n",
    "        status = \"overweight\"\n",
    "    return subj_BMIsds, status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7373/7373 [00:10<00:00, 702.26it/s]\n"
     ]
    }
   ],
   "source": [
    "Ref_Chart_dir = '/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/bmi-age-2022.csv'\n",
    "Ref_Chart = pd.read_csv(Ref_Chart_dir)\n",
    "\n",
    "phenotype = pd.read_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total.csv')\n",
    "phenotype_tmp = phenotype[['subjectkey','age', 'sex', 'weight','BMI','BMI_sds', 'BMI_status']] \n",
    "phenotype_tmp = phenotype_tmp.dropna(axis=0)\n",
    "phenotype_tmp.rename(columns={'BMI':'BMI_baseline', 'BMI_sds':'BMI_sds_baseline', 'BMI_status': 'BMI_status_baseline', 'weight':'weight_baseline'}, inplace=True)\n",
    "\n",
    "phenotype2 = pd.read_csv(\"/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD Release4.0 Tabular dataset.csv\")\n",
    "phenotype2 = phenotype2[phenotype2['eventname'] == \"2_year_follow_up_y_arm_1\"]\n",
    "phenotype2 = phenotype2.drop(['eventname','sex'], axis=1)\n",
    "phenotype2.rename(columns={'bmi':'BMI_2year', 'weight':'weight_2year'}, inplace=True)\n",
    "phenotype2 = phenotype2.reset_index(drop=True)\n",
    "for i in range(len(phenotype2['subjectkey'].values)):\n",
    "    phenotype2['subjectkey'].values[i] = phenotype2['subjectkey'].values[i].replace('_','')\n",
    "\n",
    "phenotype2_tmp = phenotype2[['subjectkey', 'BMI_2year', 'weight_2year']]\n",
    "phenotype2_tmp = phenotype2_tmp.dropna(axis=0)\n",
    "phenotype2_tmp = pd.merge(phenotype_tmp, phenotype2_tmp, how='inner', on='subjectkey' )\n",
    "# add 12 months to baseline age\n",
    "phenotype2_tmp['age_2year'] = phenotype2_tmp['age'].values + 24 \n",
    "\n",
    "# calculating BMI sds of each subject\n",
    "BMIsds = []\n",
    "BMIstatus = [] \n",
    "\n",
    "for i in tqdm(range(len(phenotype2_tmp))): \n",
    "    subj_BMIsds, status = calculating_subj_BMIsds(subj = phenotype2_tmp.iloc[i], Ref_Chart=Ref_Chart)\n",
    "    BMIsds.append(subj_BMIsds)\n",
    "    BMIstatus.append(status)\n",
    "    \n",
    "\n",
    "phenotype2_tmp['BMI_status_2year'] = np.array(BMIstatus)\n",
    "phenotype2_tmp['BMI_sds_2year'] = np.array(BMIsds) \n",
    "phenotype2_tmp['BMI_sds_change'] = phenotype2_tmp['BMI_sds_2year'].values - phenotype2_tmp['BMI_sds_baseline'].values\n",
    "phenotype2_tmp['BMI_change'] = phenotype2_tmp['BMI_2year'].values - phenotype2_tmp['BMI_baseline'].values\n",
    "phenotype2_tmp['weight_change'] = phenotype2_tmp['weight_2year'].values - phenotype2_tmp['weight_baseline'].values\n",
    "phenotype2_tmp = phenotype2_tmp.drop(['age', 'age_2year','sex', 'BMI_2year'], axis=1)\n",
    "phenotype2_final = pd.merge(phenotype2, phenotype2_tmp, how='left', left_on='subjectkey', right_on='subjectkey')\n",
    "phenotype2_final = phenotype2_final.loc[(phenotype2_final['BMI_sds_2year'] < 5) & (phenotype2_final['BMI_sds_2year'] > -5)]\n",
    "phenotype2_final.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total_2years_revised_tmp.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_template = np.zeros(len(phenotype2_final))\n",
    "for i in range(len(phenotype2_final)): \n",
    "    difference = phenotype2_final['BMI_sds_change'].values[i]\n",
    "    if difference >= 0.2 :\n",
    "        gain_template[i] = 1\n",
    "    elif  difference < 0.2 and difference > -0.2:\n",
    "        pass\n",
    "    elif difference <= - 0.2 : \n",
    "        gain_template[i] = np.nan\n",
    "\n",
    "\n",
    "loss_template = np.zeros(len(phenotype2_final))\n",
    "for i in range(len(phenotype2_final)): \n",
    "    difference = phenotype2_final['BMI_sds_change'].values[i]\n",
    "    if difference >= 0.2 :\n",
    "        loss_template[i] = np.nan\n",
    "    elif  difference < 0.2 and difference > -0.2:\n",
    "        pass\n",
    "    elif difference <= - 0.2 : \n",
    "        loss_template[i] = 1\n",
    "\n",
    "\n",
    "phenotype2_final['BMI_gain'] = gain_template\n",
    "phenotype2_final['BMI_loss'] = loss_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_gain = phenotype2_final.dropna(axis=0, subset=['BMI_gain'], inplace=False)\n",
    "phenotype_gain = phenotype_gain.drop(['BMI_loss'], axis=1)\n",
    "phenotype_gain = phenotype_gain.reset_index(drop=True)\n",
    "phenotype_gain.to_csv(\"/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total_2years_revised_BMIgain.csv\", index=False)\n",
    "\n",
    "phenotype_loss = phenotype2_final.dropna(axis=0, subset=['BMI_loss'], inplace=False)\n",
    "phenotype_loss = phenotype_loss.drop(['BMI_gain'], axis=1)\n",
    "phenotype_loss =phenotype_loss.reset_index(drop=True)\n",
    "phenotype_loss.to_csv(\"/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total_2years_revised_BMIloss.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/4139543052.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abnormal_normal['become_normal'] = np.array([1 for x in range(len(abnormal_normal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/4139543052.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_abnormal['become_overweight'] = np.array([1 for x in range(len(normal_abnormal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/4139543052.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_normal['become_overweight'] = np.array([0 for x in range(len(normal_normal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/4139543052.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_normal['become_normal'] = np.array([0 for x in range(len(normal_normal))])\n"
     ]
    }
   ],
   "source": [
    "# (baseline) abnormal to (2 year) normal acceleration \n",
    "abnormal_normal = phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'underweight') & (phenotype_gain['BMI_status_2year'] == 'normal') & (phenotype_gain['BMI_gain'] == 1)]\n",
    "abnormal_normal['become_normal'] = np.array([1 for x in range(len(abnormal_normal))])\n",
    "# (baseline) normal to (2 year) abnormal acceleration \n",
    "normal_abnormal = phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'normal') & (phenotype_gain['BMI_status_2year'] == 'overweight') & (phenotype_gain['BMI_gain'] == 1)]\n",
    "normal_abnormal['become_overweight'] = np.array([1 for x in range(len(normal_abnormal))])\n",
    "# normal to normal \n",
    "normal_normal = phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'normal') & (phenotype_gain['BMI_status_2year'] == 'normal') & (phenotype_gain['BMI_gain'] == 0)]\n",
    "normal_normal['become_overweight'] = np.array([0 for x in range(len(normal_normal))])\n",
    "normal_normal['become_normal'] = np.array([0 for x in range(len(normal_normal))])\n",
    "\n",
    "underweight = pd.concat([abnormal_normal, normal_normal])\n",
    "underweight = underweight.reset_index(drop=True)\n",
    "underweight = underweight[['subjectkey', 'become_normal']]\n",
    "overweight = pd.concat([normal_abnormal, normal_normal])\n",
    "overweight = overweight.reset_index(drop=True) \n",
    "overweight = overweight[['subjectkey', 'become_overweight']]\n",
    "\n",
    "new_df_gain = pd.merge(phenotype_gain, overweight, how='left', left_on='subjectkey', right_on='subjectkey') \n",
    "new_df_gain = pd.merge(new_df_gain, underweight, how='left', left_on='subjectkey', right_on='subjectkey') \n",
    "new_df_gain.to_csv(\"/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total_2years_revised_BMIgain.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/556775929.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abnormal_normal['become_normal'] = np.array([1 for x in range(len(abnormal_normal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/556775929.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_abnormal['become_underweight'] = np.array([1 for x in range(len(normal_abnormal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/556775929.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_normal['become_normal'] = np.array([0 for x in range(len(normal_normal))])\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/556775929.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_normal['become_underweight'] = np.array([0 for x in range(len(normal_normal))])\n"
     ]
    }
   ],
   "source": [
    "# (baseline) abnormal to (2 year) normal \n",
    "abnormal_normal = phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'overweight') & (phenotype_loss['BMI_status_2year'] == 'normal') & (phenotype_loss['BMI_loss'] == 1)]\n",
    "abnormal_normal['become_normal'] = np.array([1 for x in range(len(abnormal_normal))])\n",
    "# (baseline) normal to (2 year) abnormal \n",
    "normal_abnormal = phenotype_loss.loc[(phenotype_gain['BMI_status_baseline'] == 'normal') & (phenotype_gain['BMI_status_2year'] ==  'underweight') & (phenotype_loss['BMI_loss'] == 1)]\n",
    "normal_abnormal['become_underweight'] = np.array([1 for x in range(len(normal_abnormal))])\n",
    "\n",
    "# normal to normal \n",
    "normal_normal = phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'normal') & (phenotype_loss['BMI_status_2year'] == 'normal') & (phenotype_loss['BMI_loss'] == 0)]\n",
    "normal_normal['become_normal'] = np.array([0 for x in range(len(normal_normal))])\n",
    "normal_normal['become_underweight'] = np.array([0 for x in range(len(normal_normal))])\n",
    "\n",
    "\n",
    "overweight = pd.concat([abnormal_normal, normal_normal])\n",
    "overweight = overweight.reset_index(drop=True)\n",
    "overweight = overweight[['subjectkey', 'become_normal']]\n",
    "underweight = pd.concat([normal_abnormal, normal_normal])\n",
    "underweight = underweight.reset_index(drop=True)\n",
    "underweight = underweight[['subjectkey', 'become_underweight']]\n",
    "\n",
    "\n",
    "new_df_loss = pd.merge(phenotype_loss, overweight, how='left', left_on='subjectkey', right_on='subjectkey') \n",
    "new_df_loss = pd.merge(new_df_loss, underweight, how='left', left_on='subjectkey', right_on='subjectkey') \n",
    "new_df_loss.to_csv(\"/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total_2years_revised_BMIloss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For pretraining with BMI and transfer learning to BMI change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratification with propensity score \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from psmpy import PsmPy\n",
    "from psmpy.functions import cohenD\n",
    "\n",
    "def partition_stratified_train_test(input_df, target, cat_cov:list, num_cov: list,train_size=0.7, val_size=0.1, test_size=0.2, n_percentile=5,n_partition=4,seed=1234):\n",
    "    def concat_df(df, subject_key): \n",
    "        df_concatenated = pd.DataFrame()\n",
    "        for subj in subject_key: \n",
    "            tmp = df[df['subjectkey'] == subj]\n",
    "            df_concatenated = pd.concat([df_concatenated, tmp])\n",
    "            \n",
    "        return df_concatenated\n",
    "\n",
    "    \"\"\"\n",
    "    propensity score stratification ref: https://towardsdatascience.com/psmpy-propensity-score-matching-in-python-a3e0cd4d2631\n",
    "    \n",
    "    1) calculae propensity score there by stratify 5 percentile and assign rank \n",
    "    2) stratified split train and test data \n",
    "    3) stratified split train data to train and validation data \n",
    "    4) stratified sampling control data for train, validation and test \n",
    "    ##TODO##\n",
    "    + if subjects who have NaN values in covariates used for calculating propensity scores are assigned to only train set \n",
    "\n",
    "    n_partition=5\n",
    "    train_size = 0.8 \n",
    "    val_size = 0.125\n",
    "    test_size = 0.2 \n",
    "    >>> This is the same as split the whole dataset into train/validation/test with ratio of 0.7/0.1/0.2\n",
    "\n",
    "    n_partition=4\n",
    "    train_size = 0.65\n",
    "    test_size =0.25 \n",
    "    val_size = 0.13 (parameter for train_test_split)\n",
    "    >>> This is the same as split the whole dataset into train/validation/test with ratio of 0.65/0.1/0.25\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_partition,random_state=seed, shuffle=True)\n",
    "    q = np.linspace(0, 1, n_percentile+1)\n",
    "    labels = np.linspace(0, n_percentile-1, n_percentile)\n",
    "\n",
    "    # one hot labeling categorical values \n",
    "    #ps_df = input_df[['subjectkey', target, 'BMI_sds_change'] + cat_cov + num_cov].copy() \n",
    "    ps_df = input_df[['subjectkey', target, 'BMI_sds_baseline'] + cat_cov + num_cov].copy() \n",
    "    ps_df_tmp = ps_df.dropna(axis=0).reset_index(drop=True)\n",
    "    ps_df_cat_cov = pd.get_dummies(ps_df_tmp[cat_cov].astype('category'))\n",
    "    ps_df_tmp = ps_df_tmp.drop(columns=cat_cov, axis=1)\n",
    "    ps_df_tmp = pd.concat([ps_df_tmp, ps_df_cat_cov], axis=1)\n",
    "    \n",
    "\n",
    "    # PS calculation \n",
    "    psm = PsmPy(ps_df_tmp, treatment=target, indx='subjectkey')\n",
    "    psm.logistic_ps(balance=True)\n",
    "    ps_df_tmp = psm.predicted_data[['subjectkey','propensity_score']]\n",
    "\n",
    "    # stratify 4 percentile (test_size = 0.25)\n",
    "    percentile_class, _ = pd.qcut(ps_df_tmp['propensity_score'].values, q, labels=labels, retbins=True)\n",
    "    ps_df_tmp['percentile'] = percentile_class\n",
    "    ps_df_tmp = ps_df_tmp[['subjectkey', 'percentile']]\n",
    "    \n",
    "    \n",
    "    # separate case/control\n",
    "    case = input_df[input_df[target] == 1].reset_index(drop=True)\n",
    "    case = pd.merge(case, ps_df_tmp, how='inner', on='subjectkey')\n",
    "    control = input_df[input_df[target] == 0].reset_index(drop=True)\n",
    "    control = pd.merge(control, ps_df_tmp, how='inner', on='subjectkey')\n",
    "    num_total_case = len(case)\n",
    "    num_total_train = len(control)\n",
    "    \n",
    "\n",
    "    # stratify 10 percentile (test_size = 0.1)\n",
    "    #percentile_class, _ = pd.qcut(case['BMI_sds_change'].values, q, labels=labels, retbins=True)\n",
    "    #case['percentile'] = percentile_class\n",
    "\n",
    "    partition_result = {}\n",
    "    for i, (train_val_idx, test_idx) in enumerate(skf.split(case['subjectkey'], case['percentile'])):\n",
    "    #for i, (train_val_idx, test_idx) in enumerate(skf.split(case['subjectkey'], case['abcd.site'])):\n",
    "        # assign samples knocked out by nan filtering for propensity scores to train set.\n",
    "        case_add = input_df[['subjectkey', target, 'BMI_sds_change'] + cat_cov + num_cov].copy() \n",
    "        case_add = case_add[case_add.isna().any(axis=1)]\n",
    "        case_add = case_add[case_add[target] == 1]\n",
    "        case_add = case_add[['subjectkey']]\n",
    "        case_add['partition%s' % i] = ['train' for _ in range(len(case_add))]\n",
    "\n",
    "        # split train/test\n",
    "        case_test = case.loc[test_idx]\n",
    "        case_train_val = case.loc[train_val_idx].reset_index(drop=True)\n",
    "        control_test = control.groupby('percentile', group_keys=False).apply(lambda x: x.sample(frac=len(case_test)/len(control), random_state=seed))   # stratified random sampling, where len(case_test) == len(control_test) \n",
    "        control_test_removed = control.drop(axis=0, index=control_test.index).reset_index(drop=True)\n",
    "        control_train_val = control_test_removed.groupby('percentile', group_keys=False).apply(lambda x: x.sample(frac=(len(case_train_val)+len(case_add))/len(control_test_removed), random_state=seed))\n",
    "        #control_train_val = control_test_removed.groupby('percentile', group_keys=False).apply(lambda x: x.sample(frac=len(case_train_val)/len(control_test_removed)))\n",
    "        \n",
    "        \n",
    "        # split train into train/val\n",
    "        subjectkey_case_train_val, percentile_case_train_val = case_train_val['subjectkey'].values, case_train_val['percentile'].values\n",
    "        subjectkey_case_train, subjectkey_case_val, _, _ = train_test_split(subjectkey_case_train_val, percentile_case_train_val, test_size=0.125, shuffle=True, random_state=seed+1, stratify=percentile_case_train_val)\n",
    "        #subjectkey_case_train, subjectkey_case_val, _, _ = train_test_split(subjectkey_case_train_val, percentile_case_train_val, test_size=0.13,random_state=seed+1, shuffle=True, stratify=percentile_case_train_val)\n",
    "        case_val = concat_df(case_train_val, subjectkey_case_val)\n",
    "        case_train = concat_df(case_train_val, subjectkey_case_train)\n",
    "\n",
    "        \n",
    "        # stratified sampling control of train/val\n",
    "        control_val = control_train_val.groupby('percentile', group_keys=False).apply(lambda x: x.sample(frac=len(case_val)/len(control_train_val), random_state=seed))\n",
    "        control_train = control_train_val.drop(axis=0, index=control_val.index).reset_index(drop=True)\n",
    "        #control_train = pd.concat([control_train.drop(columns='percentile'), nan_train], axis=0)\n",
    "        \n",
    "\n",
    "        \n",
    "        case_test['partition%s' % i] = ['test' for _ in range(len(case_test))]\n",
    "        case_val['partition%s' % i] = ['val' for _ in range(len(case_val))]\n",
    "        case_train['partition%s' % i] = ['train' for _ in range(len(case_train))]\n",
    "        control_test['partition%s' % i] = ['test' for _ in range(len(control_test))]\n",
    "        control_val['partition%s' % i] = ['val' for _ in range(len(control_val))]\n",
    "        control_train['partition%s' % i] = ['train' for _ in range(len(control_train))]\n",
    "\n",
    "        partition_df = pd.concat([case_train, control_train, case_val, control_val, case_test, control_test])\n",
    "        partition_df = partition_df[['subjectkey', 'partition%s' % i]]\n",
    "        partition_df = pd.concat([partition_df, case_add], axis=0)\n",
    "        \n",
    "        partition_result['partition%s' % i] = partition_df\n",
    "\n",
    "    final_df = input_df.drop(columns=cat_cov + num_cov).copy()\n",
    "    for i in range(n_partition):\n",
    "        final_df = pd.merge(final_df, partition_result['partition%s' % i], how='left', on='subjectkey')\n",
    "\n",
    "    return final_df\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def partition_train_test_baseline(baseline_data, longitudinal_data,  train_size=0.75, val_size=0.05, test_size=0.2, n_partition=4, seed=1234): \n",
    "    baseline_data_tmp = baseline_data[['subjectkey','BMI_baseline', 'BMI_sds_baseline']]\n",
    "    baseline_data_tmp = baseline_data_tmp.dropna(axis=0)\n",
    "\n",
    "    num_total = len(baseline_data)\n",
    "    num_train = int(num_total * train_size)\n",
    "    num_test = int(num_total * test_size)\n",
    "    num_val  = num_total - num_train - num_test\n",
    "\n",
    "    phenotype_partition_final = {}\n",
    "    for i in range(n_partition): \n",
    "        longitudinal_data_tmp = longitudinal_data[['subjectkey', 'partition%s' % i ]]\n",
    "        phenotype_partition = pd.merge(baseline_data_tmp, longitudinal_data_tmp, how='left', left_on='subjectkey', right_on='subjectkey')\n",
    "        phenotype_partition = phenotype_partition.drop(['BMI_baseline', 'BMI_sds_baseline'], axis=1)\n",
    "        test_2y = phenotype_partition[phenotype_partition['partition%s' % i] == 'test']\n",
    "        val_2y = phenotype_partition[phenotype_partition['partition%s' % i] == 'val']\n",
    "        train_2y = phenotype_partition[phenotype_partition['partition%s' % i] == 'train']\n",
    "\n",
    "        num_test_tmp = num_test - len(test_2y)\n",
    "        num_val_tmp = num_val - len(val_2y)\n",
    "        num_train_tmp = num_train - len(train_2y)\n",
    "\n",
    "        phenotype_partition_all = phenotype_partition.drop(index=test_2y.index, axis=0).drop(index=val_2y.index, axis=0).drop(index=train_2y.index, axis=0)\n",
    "        #phenotype_partition_all = phenotype_partition_all.sample(frac=1, random_state=seed).reset_index(drop=True)  # shuffling하고 index reset\n",
    "\n",
    "        phenotype_partition_train = phenotype_partition_all.iloc[:num_train_tmp]\n",
    "        phenotype_partition_test = phenotype_partition_all.iloc[num_train_tmp:num_train_tmp+num_test_tmp]\n",
    "        phenotype_partition_val = phenotype_partition_all.iloc[num_train_tmp+num_test_tmp:]\n",
    "\n",
    "\n",
    "        phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
    "        phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
    "        phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
    "        \n",
    "        phenotype_partition_final_tmp = pd.concat([phenotype_partition_train, train_2y, phenotype_partition_val, val_2y, phenotype_partition_test, test_2y])\n",
    "        phenotype_partition_final['partition%s' % i] = phenotype_partition_final_tmp\n",
    "        \n",
    "\n",
    "    partitioned_data_baseline = baseline_data\n",
    "    for i in range(n_partition): \n",
    "        partitioned_data_baseline = pd.merge(partitioned_data_baseline, phenotype_partition_final['partition%s' % i], how='left', left_on='subjectkey', right_on='subjectkey')\n",
    "\n",
    "    return partitioned_data_baseline\n",
    "\n",
    "\n",
    "\n",
    "def check_partition(input_df, target='become_overweight', split='train', n_percentile=5, n_partition=4): \n",
    "    q = np.linspace(0, 1, n_percentile+1)\n",
    "    labels = np.linspace(0, n_percentile-1, n_percentile)\n",
    "\n",
    "    # separate case/control\n",
    "    case = input_df[input_df[target] == 1].reset_index(drop=True)\n",
    "    control = input_df[input_df[target] == 0].reset_index(drop=True)\n",
    "    num_total_case = len(case)\n",
    "    num_total_train = len(control)\n",
    "\n",
    "    # stratify 10 percentile (test_size = 0.1)\n",
    "    percentile_class, _ = pd.qcut(case['BMI_sds_change'].values, q, labels=labels, retbins=True)\n",
    "    case['percentile'] = percentile_class\n",
    "\n",
    "    check = pd.merge(input_df, case[['subjectkey', 'percentile']], how='inner', on='subjectkey')\n",
    "\n",
    "    for i in range(n_partition): \n",
    "        tmp = check[check['partition%s' % i] == split]\n",
    "        print(\"In partition{}, {} have following counts for each percentile: {}\".format(i, split, tmp['percentile'].value_counts().values.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ps_df_tmp['percentile'] = percentile_class\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In partition0, train have following counts for each percentile: [42, 42, 41, 39, 38, 36, 35, 35, 33, 31]\n",
      "In partition1, train have following counts for each percentile: [45, 40, 39, 39, 38, 37, 36, 35, 32, 31]\n",
      "In partition2, train have following counts for each percentile: [44, 41, 41, 39, 37, 35, 34, 34, 34, 33]\n",
      "In partition3, train have following counts for each percentile: [42, 41, 41, 38, 37, 36, 35, 35, 34, 33]\n",
      "In partition4, train have following counts for each percentile: [41, 40, 38, 38, 38, 37, 37, 36, 34, 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n"
     ]
    }
   ],
   "source": [
    "cat_cov = ['sex', 'abcd.site', 'race.ethnicity'] \n",
    "num_cov = ['age', 'high.educ', 'income'] \n",
    "phenotype = pd.read_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total.csv')\n",
    "phenotype_tmp = phenotype.rename(columns={'BMI_sds': 'BMI_sds_baseline', 'BMI': 'BMI_baseline'})\n",
    "new_df_gain_tmp = new_df_gain.drop(columns=['age', 'income'])   # remove duplicated columns\n",
    "new_df_gain_tmp = pd.merge(new_df_gain_tmp, phenotype_tmp[['subjectkey'] + cat_cov + num_cov], how='inner', on='subjectkey')\n",
    "partitioned_data_2yafter = partition_stratified_train_test(new_df_gain_tmp, 'become_overweight', cat_cov=cat_cov, num_cov=num_cov, n_percentile=10, n_partition=5, seed=1234)\n",
    "partitioned_data_baseline = partition_train_test_baseline(baseline_data=phenotype_tmp , longitudinal_data=partitioned_data_2yafter, n_partition=5, seed=1234)\n",
    "partitioned_data_2yafter.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_2years_become_overweight_10PS_stratified_partitioned_5fold.csv', index=False)\n",
    "partitioned_data_baseline.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_for_pretraining_2y_after_become_overweight_10PS_stratified_5fold.csv', index=False)\n",
    "\n",
    "check_partition(partitioned_data_2yafter, target='become_overweight', split='train', n_percentile=10, n_partition=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ps_df_tmp['percentile'] = percentile_class\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_train['partition%s' % i] = ['train' for j in range(len(phenotype_partition_train))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_test['partition%s' % i] = ['test' for j in range(len(phenotype_partition_test))]\n",
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_2459/1777504985.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phenotype_partition_val['partition%s' % i] = ['val' for j in range(len(phenotype_partition_val))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In partition0, train have following counts for each percentile: [12, 11, 10, 9, 9, 9, 9, 8, 8, 7]\n",
      "In partition1, train have following counts for each percentile: [12, 11, 10, 10, 9, 9, 8, 8, 8, 7]\n",
      "In partition2, train have following counts for each percentile: [12, 10, 10, 10, 9, 9, 9, 8, 8, 7]\n",
      "In partition3, train have following counts for each percentile: [12, 10, 10, 10, 10, 9, 9, 8, 8, 7]\n",
      "In partition4, train have following counts for each percentile: [12, 11, 10, 10, 9, 9, 9, 8, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "cat_cov = ['sex', 'abcd.site', 'race.ethnicity'] \n",
    "num_cov = ['age', 'high.educ', 'income'] \n",
    "phenotype = pd.read_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total.csv')\n",
    "phenotype_tmp = phenotype.rename(columns={'BMI_sds': 'BMI_sds_baseline', 'BMI': 'BMI_baseline'})\n",
    "new_df_gain_tmp = new_df_gain.drop(columns=['age', 'income'])   # remove duplicated columns\n",
    "new_df_gain_tmp = pd.merge(new_df_gain_tmp, phenotype_tmp[['subjectkey'] + cat_cov + num_cov], how='inner', on='subjectkey')\n",
    "partitioned_data_1yafter = partition_stratified_train_test(new_df_gain_tmp, 'become_normal', cat_cov=cat_cov, num_cov=num_cov, n_percentile=10, n_partition=5, seed=1234)\n",
    "partitioned_data_baseline = partition_train_test_baseline(baseline_data=phenotype_tmp , longitudinal_data=partitioned_data_1yafter, n_partition=5, seed=1234)\n",
    "partitioned_data_1yafter.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_2years_become_normal_10PS_stratified_partitioned_5fold.csv', index=False)\n",
    "partitioned_data_baseline.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_for_pretraining_2y_after_become_normal_10PS_stratified_5fold.csv', index=False)\n",
    "\n",
    "check_partition(partitioned_data_1yafter, target='become_normal', split='train', n_percentile=10, n_partition=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['become_underweight'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m new_df_gain_tmp \u001b[38;5;241m=\u001b[39m new_df_gain\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m'\u001b[39m])   \u001b[38;5;66;03m# remove duplicated columns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m new_df_gain_tmp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(new_df_gain_tmp, phenotype_tmp[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubjectkey\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m cat_cov \u001b[38;5;241m+\u001b[39m num_cov], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubjectkey\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m partitioned_data_1yafter \u001b[38;5;241m=\u001b[39m \u001b[43mpartition_stratified_train_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_df_gain_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbecome_underweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_cov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_cov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_percentile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_partition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1234\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m partitioned_data_baseline \u001b[38;5;241m=\u001b[39m partition_train_test_baseline(baseline_data\u001b[38;5;241m=\u001b[39mphenotype_tmp , longitudinal_data\u001b[38;5;241m=\u001b[39mpartitioned_data_1yafter, n_partition\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234\u001b[39m)\n\u001b[1;32m      9\u001b[0m partitioned_data_1yafter\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_2years_become_underweight_10PS_stratified_partitioned_5fold.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[26], line 47\u001b[0m, in \u001b[0;36mpartition_stratified_train_test\u001b[0;34m(input_df, target, cat_cov, num_cov, train_size, val_size, test_size, n_percentile, n_partition, seed)\u001b[0m\n\u001b[1;32m     43\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, n_percentile\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_percentile)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# one hot labeling categorical values \u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#ps_df = input_df[['subjectkey', target, 'BMI_sds_change'] + cat_cov + num_cov].copy() \u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m ps_df \u001b[38;5;241m=\u001b[39m \u001b[43minput_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubjectkey\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBMI_sds_baseline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcat_cov\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_cov\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy() \n\u001b[1;32m     48\u001b[0m ps_df_tmp \u001b[38;5;241m=\u001b[39m ps_df\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m ps_df_cat_cov \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(ps_df_tmp[cat_cov]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3810'>3811</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3811'>3812</a>\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3812'>3813</a>\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3814'>3815</a>\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py?line=3815'>3816</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6066'>6067</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6067'>6068</a>\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6069'>6070</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6071'>6072</a>\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6072'>6073</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6073'>6074</a>\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6129'>6130</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6131'>6132</a>\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=6132'>6133</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['become_underweight'] not in index\""
     ]
    }
   ],
   "source": [
    "cat_cov = ['sex', 'abcd.site', 'race.ethnicity'] \n",
    "num_cov = ['age', 'high.educ', 'income'] \n",
    "phenotype = pd.read_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/ABCD_phenotype_total.csv')\n",
    "phenotype_tmp = phenotype.rename(columns={'BMI_sds': 'BMI_sds_baseline', 'BMI': 'BMI_baseline'})\n",
    "new_df_gain_tmp = new_df_gain.drop(columns=['age', 'income'])   # remove duplicated columns\n",
    "new_df_gain_tmp = pd.merge(new_df_gain_tmp, phenotype_tmp[['subjectkey'] + cat_cov + num_cov], how='inner', on='subjectkey')\n",
    "partitioned_data_1yafter = partition_stratified_train_test(new_df_gain_tmp, 'become_underweight', cat_cov=cat_cov, num_cov=num_cov, n_percentile=10, n_partition=5, seed=1234)\n",
    "partitioned_data_baseline = partition_train_test_baseline(baseline_data=phenotype_tmp , longitudinal_data=partitioned_data_1yafter, n_partition=5, seed=1234)\n",
    "partitioned_data_1yafter.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_2years_become_underweight_10PS_stratified_partitioned_5fold.csv', index=False)\n",
    "partitioned_data_baseline.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/phenotype_data/10PS/ABCD_phenotype_total_for_pretraining_2y_after_become_underweight_10PS_stratified_5fold.csv', index=False)\n",
    "\n",
    "check_partition(partitioned_data_1yafter, target='become_underweight', split='train', n_percentile=10, n_partition=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "underweight -> underweight: 35\n",
      "underweight -> normal: 128\n",
      "normal -> normal: 1467\n",
      "normal -> overweight: 516\n",
      "overweight -> overweight: 1090\n",
      "underweight -> overweight: 6\n"
     ]
    }
   ],
   "source": [
    "num_underweight_underweight = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'underweight') & (phenotype_gain['BMI_status_2year'] == 'underweight') & (phenotype_gain['BMI_gain'] == 0)]) \n",
    "num_underweight_normal = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'underweight') & (phenotype_gain['BMI_status_2year'] == 'normal') & (phenotype_gain['BMI_gain'] == 1)]) \n",
    "num_normal_normal = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'normal') & (phenotype_gain['BMI_status_2year'] == 'normal') & (phenotype_gain['BMI_gain'] == 0)]) \n",
    "num_normal_overweight = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'normal') & (phenotype_gain['BMI_status_2year'] == 'overweight') & (phenotype_gain['BMI_gain'] == 1)]) \n",
    "num_overweight_overweight = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'overweight') & (phenotype_gain['BMI_status_2year'] == 'overweight') & (phenotype_gain['BMI_gain'] == 0)])\n",
    "num_underweight_overweight = len(phenotype_gain.loc[(phenotype_gain['BMI_status_baseline'] == 'underweight') & (phenotype_gain['BMI_status_2year'] == 'overweight') & (phenotype_gain['BMI_gain'] == 1)])\n",
    "\n",
    "print(\"underweight -> underweight: {}\".format(num_underweight_underweight))\n",
    "print(\"underweight -> normal: {}\".format(num_underweight_normal))\n",
    "print(\"normal -> normal: {}\".format(num_normal_normal))\n",
    "print(\"normal -> overweight: {}\".format(num_normal_overweight))\n",
    "print(\"overweight -> overweight: {}\".format(num_overweight_overweight))\n",
    "print(\"underweight -> overweight: {}\".format(num_underweight_overweight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overweight -> overweight: 1090\n",
      "overweight -> normal: 322\n",
      "overweight -> underweight: 2\n",
      "normal -> normal: 1467\n",
      "normal -> underweight: 123\n",
      "underweight -> underweight: 35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_overweight_overweight = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'overweight') & (phenotype_loss['BMI_status_2year'] == 'overweight') & (phenotype_loss['BMI_loss'] == 0)])\n",
    "num_overweight_normal = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'overweight') & (phenotype_loss['BMI_status_2year'] == 'normal') & (phenotype_loss['BMI_loss'] == 1)])\n",
    "num_overweight_underweight = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'overweight') & (phenotype_loss['BMI_status_2year'] == 'underweight') & (phenotype_loss['BMI_loss'] == 1)])\n",
    "num_normal_normal = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'normal') & (phenotype_loss['BMI_status_2year'] == 'normal') & (phenotype_loss['BMI_loss'] == 0)]) \n",
    "num_normal_underweight = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'normal') & (phenotype_loss['BMI_status_2year'] == 'underweight') & (phenotype_loss['BMI_loss'] == 1)]) \n",
    "num_underweight_underweight = len(phenotype_loss.loc[(phenotype_loss['BMI_status_baseline'] == 'underweight') & (phenotype_loss['BMI_status_2year'] == 'underweight') & (phenotype_loss['BMI_loss'] == 0)]) \n",
    "\n",
    "\n",
    "print(\"overweight -> overweight: {}\".format(num_overweight_overweight))\n",
    "print(\"overweight -> normal: {}\".format(num_overweight_normal))\n",
    "print(\"overweight -> underweight: {}\".format(num_overweight_underweight))\n",
    "print(\"normal -> normal: {}\".format(num_normal_normal))\n",
    "print(\"normal -> underweight: {}\".format(num_normal_underweight))\n",
    "print(\"underweight -> underweight: {}\".format(num_underweight_underweight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = phenotype[['subjectkey', 'sex']]\n",
    "phenotype_gain_sex = pd.merge(phenotype_gain, sex, on='subjectkey', how='inner')\n",
    "phenotype_loss_sex = pd.merge(phenotype_loss, sex, on='subjectkey', how='inner')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "underweight -> underweight: 20\n",
      "underweight -> normal: 65\n",
      "normal -> normal: 787\n",
      "normal -> overweight: 270\n",
      "overweight -> overweight: 604\n",
      "underweight -> overweight: 4\n"
     ]
    }
   ],
   "source": [
    "num_underweight_underweight = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'underweight') & (phenotype_gain_sex['BMI_status_2year'] == 'underweight') & (phenotype_gain_sex['BMI_gain'] == 0) & (phenotype_gain_sex['sex'] == 1)]) \n",
    "num_underweight_normal = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'underweight') & (phenotype_gain_sex['BMI_status_2year'] == 'normal') & (phenotype_gain_sex['BMI_gain'] == 1) & (phenotype_gain_sex['sex'] == 1)]) \n",
    "num_normal_normal = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'normal') & (phenotype_gain_sex['BMI_status_2year'] == 'normal') & (phenotype_gain_sex['BMI_gain'] == 0) & (phenotype_gain_sex['sex'] == 1)]) \n",
    "num_normal_overweight = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'normal') & (phenotype_gain_sex['BMI_status_2year'] == 'overweight') & (phenotype_gain_sex['BMI_gain'] == 1) & (phenotype_gain_sex['sex'] == 1)]) \n",
    "num_overweight_overweight = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'overweight') & (phenotype_gain_sex['BMI_status_2year'] == 'overweight') & (phenotype_gain_sex['BMI_gain'] == 0) & (phenotype_gain_sex['sex'] == 1)])\n",
    "num_underweight_overweight = len(phenotype_gain_sex.loc[(phenotype_gain_sex['BMI_status_baseline'] == 'underweight') & (phenotype_gain_sex['BMI_status_2year'] == 'overweight') & (phenotype_gain_sex['BMI_gain'] == 1) & (phenotype_gain_sex['sex'] == 1)])\n",
    "\n",
    "print(\"underweight -> underweight: {}\".format(num_underweight_underweight))\n",
    "print(\"underweight -> normal: {}\".format(num_underweight_normal))\n",
    "print(\"normal -> normal: {}\".format(num_normal_normal))\n",
    "print(\"normal -> overweight: {}\".format(num_normal_overweight))\n",
    "print(\"overweight -> overweight: {}\".format(num_overweight_overweight))\n",
    "print(\"underweight -> overweight: {}\".format(num_underweight_overweight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overweight -> overweight: 604\n",
      "overweight -> normal: 171\n",
      "overweight -> underweight: 2\n",
      "normal -> normal: 787\n",
      "normal -> underweight: 84\n",
      "underweight -> underweight: 20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_overweight_overweight = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'overweight') & (phenotype_loss_sex['BMI_status_2year'] == 'overweight') & (phenotype_loss_sex['BMI_loss'] == 0) & (phenotype_loss_sex['sex'] == 1)])\n",
    "num_overweight_normal = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'overweight') & (phenotype_loss_sex['BMI_status_2year'] == 'normal') & (phenotype_loss_sex['BMI_loss'] == 1) & (phenotype_loss_sex['sex'] == 1)])\n",
    "num_overweight_underweight = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'overweight') & (phenotype_loss_sex['BMI_status_2year'] == 'underweight') & (phenotype_loss_sex['BMI_loss'] == 1) & (phenotype_loss_sex['sex'] == 1)])\n",
    "num_normal_normal = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'normal') & (phenotype_loss_sex['BMI_status_2year'] == 'normal') & (phenotype_loss_sex['BMI_loss'] == 0) & (phenotype_loss_sex['sex'] == 1)]) \n",
    "num_normal_underweight = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'normal') & (phenotype_loss_sex['BMI_status_2year'] == 'underweight') & (phenotype_loss_sex['BMI_loss'] == 1) & (phenotype_loss_sex['sex'] == 1)]) \n",
    "num_underweight_underweight = len(phenotype_loss_sex.loc[(phenotype_loss_sex['BMI_status_baseline'] == 'underweight') & (phenotype_loss_sex['BMI_status_2year'] == 'underweight') & (phenotype_loss_sex['BMI_loss'] == 0) & (phenotype_loss_sex['sex'] == 1)]) \n",
    "\n",
    "\n",
    "print(\"overweight -> overweight: {}\".format(num_overweight_overweight))\n",
    "print(\"overweight -> normal: {}\".format(num_overweight_normal))\n",
    "print(\"overweight -> underweight: {}\".format(num_overweight_underweight))\n",
    "print(\"normal -> normal: {}\".format(num_normal_normal))\n",
    "print(\"normal -> underweight: {}\".format(num_normal_underweight))\n",
    "print(\"underweight -> underweight: {}\".format(num_underweight_underweight))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
