{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "import nibabel as nib\n",
    "import json\n",
    "\n",
    "from monai.transforms import Compose, AddChannel, Resize \n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def extracting_score(mask_img_dir, subject_list, subject_file_list): \n",
    "    # loading mask image\n",
    "    mask = nib.load(mask_img_dir) \n",
    "    mask = np.array(mask.dataobj)\n",
    "\n",
    "    # calculating mean attribution scores per ROI \n",
    "    seg_attr_result = {}\n",
    "    for i in tqdm(np.unique(mask)):\n",
    "        if i == 0: \n",
    "            pass \n",
    "        else:  \n",
    "            seg_mask = np.where(mask != i, 0, 1)\n",
    "            transform = Compose([AddChannel(), Resize((128, 128, 128))])\n",
    "            seg_mask = transform(seg_mask)[0, :, :, :] \n",
    "            seg_subj_attr_result = []\n",
    "            for subj in subject_file_list: \n",
    "                # standardizing subject's attribution score across the whole brain\n",
    "                subj_img = np.load(subj)\n",
    "                subj_img = (subj_img - np.mean(subj_img)) / np.std(subj_img)\n",
    "                # masking ROI\n",
    "                seg_subj_attr = subj_img * seg_mask\n",
    "                # calculating mean attr score per ROI\n",
    "                if np.sum(seg_mask) == 0: \n",
    "                    seg_subj_attr_norm = 0 \n",
    "                else: \n",
    "                    seg_subj_attr_norm = np.sum(seg_subj_attr) / np.sum(seg_mask)\n",
    "                seg_subj_attr_result.append(seg_subj_attr_norm)\n",
    "            seg_attr_result[\"%s\" % i] = seg_subj_attr_result \n",
    "\n",
    "    df = {'subjectkey': subject_list}\n",
    "    df.update(seg_attr_result)\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "\n",
    "def normalizing(df:pd.DataFrame): \n",
    "    col_list = list(df.keys())[1:]\n",
    "    for i in col_list: \n",
    "        arr = df[i].values\n",
    "        mean = np.mean(arr)\n",
    "        stdev = np.std(arr)\n",
    "        df[i] = (arr - mean) / stdev\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI-sds baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### HarvardOxford (FSL)\n",
    "\"\"\"\n",
    "ref: https://github.com/dmascali/mni2atlas\n",
    "\"\"\"\n",
    "# cortical\n",
    "HarvardOxford_cort_mask = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/HarvardOxford-cort-maxprob-thr25-1mm.nii.gz\"\n",
    "HarvardOxford_cort_LUT = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/cort_label.json\"\n",
    "\n",
    "# subcortical\n",
    "HarvardOxford_subcort_mask = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/HarvardOxford-sub-maxprob-thr25-1mm.nii.gz\"\n",
    "HarvardOxford_subcort_LUT = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/subcort_label.json\"\n",
    "\n",
    "mask_img_dir_list = [HarvardOxford_cort_mask, HarvardOxford_subcort_mask]\n",
    "mask_LUT_dir_list = [HarvardOxford_cort_LUT, HarvardOxford_subcort_LUT]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "IG_map_dir = \"/Users/wangheehwan/Desktop/CNN_for_BMI/interpretation/ABCD/MNI/BMI_sds\"\n",
    "\n",
    "\n",
    "# gathering the name of subject files\n",
    "subject_file_list = []\n",
    "subject_list = [] \n",
    "\n",
    "for file in  glob.glob(IG_map_dir + '/*'): \n",
    "    subject_file_list.append(file)\n",
    "    subject_list.append(os.path.split(file)[-1].replace('.npy', ''))\n",
    "\n",
    "df_final = pd.DataFrame({'subjectkey': subject_list})\n",
    "for (mask_img_dir, mask_LUT_dir) in zip(mask_img_dir_list, mask_LUT_dir_list):\n",
    "    # calculating mean attribution score per ROI \n",
    "    df = extracting_score(mask_img_dir=mask_img_dir, subject_file_list=subject_file_list, subject_list=subject_list)\n",
    "\n",
    "    # indexing ROI name based on the number of ROI \n",
    "    with open(mask_LUT_dir, 'r') as file:\n",
    "        LUT = json.load(file) \n",
    "    df.columns = ['subjectkey'] + list(LUT.values())\n",
    "    df_final = pd.merge(df_final, df, how='inner', on='subjectkey')\n",
    "\n",
    "# remove duplicated ROI\n",
    "df_final = df_final.drop(['Left Cerebral White Matter', 'Left Cerebral Cortex', 'Right Cerebral White Matter', 'Right Cerebral Cortex'], axis=1)\n",
    "\n",
    "# Summary feature importance \n",
    "ROI_list = list(df_final.keys()[1:])\n",
    "ROI_mean = [] \n",
    "ROI_std = []\n",
    "# getting mean score \n",
    "for ROI in ROI_list:\n",
    "    ROI_mean.append(np.mean(df_final[ROI]))\n",
    "    ROI_std.append(np.std(df_final[ROI]))\n",
    "ROI_mean_sorted = np.sort(ROI_mean)[::-1]\n",
    "ROI_mean_sorted = np.where(ROI_mean_sorted == 0, np.nan, ROI_mean_sorted) \n",
    "ROI_std_sorted = np.array(ROI_std)[np.argsort(ROI_mean)[::-1]]\n",
    "ROI_std_sorted = np.where(ROI_std_sorted == 0, np.nan, ROI_std_sorted)\n",
    "index_sorted = [index[i] for i in np.argsort(ROI_mean)[::-1]] \n",
    "\n",
    "df_result = pd.DataFrame(data=index_sorted, columns=['ROI'])\n",
    "df_result['attribution_mean'] = ROI_mean_sorted\n",
    "df_result['Rank'] = [i+1 for i in range(len(index_sorted))]\n",
    "\n",
    "\n",
    "df_result.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/paper/experiments/XAI/Feature_Importance_HarvardOxford_BMI_sds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After 1 year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 'after1y'        #options = ['after1y', 'after2y'] \n",
    "### HarvardOxford (FSL)\n",
    "\"\"\"\n",
    "ref: https://github.com/dmascali/mni2atlas\n",
    "\"\"\"\n",
    "# cortical\n",
    "HarvardOxford_cort_mask = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/HarvardOxford-cort-maxprob-thr25-1mm.nii.gz\"\n",
    "HarvardOxford_cort_LUT = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/cort_label.json\"\n",
    "\n",
    "# subcortical\n",
    "HarvardOxford_subcort_mask = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/HarvardOxford-sub-maxprob-thr25-1mm.nii.gz\"\n",
    "HarvardOxford_subcort_LUT = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/subcort_label.json\"\n",
    "\n",
    "mask_img_dir_list = [HarvardOxford_cort_mask, HarvardOxford_subcort_mask]\n",
    "mask_LUT_dir_list = [HarvardOxford_cort_LUT, HarvardOxford_subcort_LUT]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n",
      "100%|██████████| 48/48 [00:02<00:00, 16.01it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 15.03it/s]\n"
     ]
    }
   ],
   "source": [
    "IG_map_dir = \"/Users/wangheehwan/Desktop/CNN_for_BMI/interpretation\"\n",
    "# get every partition data\n",
    "OBESITY_attr_dir = [] \n",
    "OBESITY_attr_dir.append(os.path.join(*[IG_map_dir, year,'partition0']))\n",
    "OBESITY_attr_dir.append(os.path.join(*[IG_map_dir, year,'partition1']))\n",
    "OBESITY_attr_dir.append(os.path.join(*[IG_map_dir, year,'partition2']))\n",
    "OBESITY_attr_dir.append(os.path.join(*[IG_map_dir, year,'partition3']))\n",
    "OBESITY_attr_dir.append(os.path.join(*[IG_map_dir, year,'partition4']))\n",
    "\n",
    "# gathering the name of subject files\n",
    "subject_file_list = []\n",
    "subject_list = [] \n",
    "for OBESITY_attr_dir_partition in OBESITY_attr_dir:\n",
    "    for file in  glob.glob(OBESITY_attr_dir_partition + '/*'): \n",
    "        subject_file_list.append(file)\n",
    "        subject_list.append(os.path.split(file)[-1].replace('.npy', ''))\n",
    "\n",
    "df_final = pd.DataFrame({'subjectkey': subject_list})\n",
    "for (mask_img_dir, mask_LUT_dir) in zip(mask_img_dir_list, mask_LUT_dir_list):\n",
    "    # calculating mean attribution score per ROI \n",
    "    df = extracting_score(mask_img_dir=mask_img_dir, subject_file_list=subject_file_list, subject_list=subject_list)\n",
    "\n",
    "    # indexing ROI name based on the number of ROI \n",
    "    with open(mask_LUT_dir, 'r') as file:\n",
    "        LUT = json.load(file) \n",
    "    df.columns = ['subjectkey'] + list(LUT.values())\n",
    "    df_final = pd.merge(df_final, df, how='inner', on='subjectkey')\n",
    "\n",
    "# remove duplicated ROI\n",
    "df_final = df_final.drop(['Left Cerebral White Matter', 'Left Cerebral Cortex', 'Right Cerebral White Matter', 'Right Cerebral Cortex'], axis=1)\n",
    "\n",
    "# Summary feature importance \n",
    "ROI_list = list(df_final.keys()[1:])\n",
    "ROI_mean = [] \n",
    "ROI_std = []\n",
    "# getting mean score \n",
    "for ROI in ROI_list:\n",
    "    ROI_mean.append(np.mean(df_final[ROI]))\n",
    "    ROI_std.append(np.std(df_final[ROI]))\n",
    "ROI_mean_sorted = np.sort(ROI_mean)[::-1]\n",
    "ROI_mean_sorted = np.where(ROI_mean_sorted == 0, np.nan, ROI_mean_sorted) \n",
    "ROI_std_sorted = np.array(ROI_std)[np.argsort(ROI_mean)[::-1]]\n",
    "ROI_std_sorted = np.where(ROI_std_sorted == 0, np.nan, ROI_std_sorted)\n",
    "index_sorted = [index[i] for i in np.argsort(ROI_mean)[::-1]] \n",
    "\n",
    "df_result = pd.DataFrame(data=index_sorted, columns=['ROI'])\n",
    "df_result['attribution_mean'] = ROI_mean_sorted\n",
    "df_result['Rank'] = [i+1 for i in range(len(index_sorted))]\n",
    "\n",
    "\n",
    "df_result.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/paper/experiments/XAI/Feature_Importance_HarvardOxford_become_overweight_aftery.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After 2y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 'after2y'        #options = ['after1y', 'after2y'] \n",
    "### HarvardOxford (FSL)\n",
    "\"\"\"\n",
    "ref: https://github.com/dmascali/mni2atlas\n",
    "\"\"\"\n",
    "# cortical\n",
    "HarvardOxford_cort_mask = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/HarvardOxford-cort-maxprob-thr25-1mm.nii.gz\"\n",
    "HarvardOxford_cort_LUT = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/cort_label.json\"\n",
    "\n",
    "# subcortical\n",
    "HarvardOxford_subcort_mask = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/HarvardOxford-sub-maxprob-thr25-1mm.nii.gz\"\n",
    "HarvardOxford_subcort_LUT = \"/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/clustering/atlas/HarvardOxford/subcort_label.json\"\n",
    "\n",
    "mask_img_dir_list = [HarvardOxford_cort_mask, HarvardOxford_subcort_mask]\n",
    "mask_LUT_dir_list = [HarvardOxford_cort_LUT, HarvardOxford_subcort_LUT]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask_img_dir_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/wangheehwan/Desktop/CNN_for_BMI/paper/code/feature_importance.ipynb 셀 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangheehwan/Desktop/CNN_for_BMI/paper/code/feature_importance.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         subject_list\u001b[39m.\u001b[39mappend(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplit(file)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangheehwan/Desktop/CNN_for_BMI/paper/code/feature_importance.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m df_final \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39msubjectkey\u001b[39m\u001b[39m'\u001b[39m: subject_list})\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/wangheehwan/Desktop/CNN_for_BMI/paper/code/feature_importance.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m (mask_img_dir, mask_LUT_dir) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(mask_img_dir_list, mask_LUT_dir_list):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangheehwan/Desktop/CNN_for_BMI/paper/code/feature_importance.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m# calculating mean attribution score per ROI \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangheehwan/Desktop/CNN_for_BMI/paper/code/feature_importance.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     df \u001b[39m=\u001b[39m extracting_score(mask_img_dir\u001b[39m=\u001b[39mmask_img_dir, subject_file_list\u001b[39m=\u001b[39msubject_file_list, subject_list\u001b[39m=\u001b[39msubject_list)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangheehwan/Desktop/CNN_for_BMI/paper/code/feature_importance.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# indexing ROI name based on the number of ROI \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mask_img_dir_list' is not defined"
     ]
    }
   ],
   "source": [
    "IG_map_dir = \"/Users/wangheehwan/Desktop/CNN_for_BMI/interpretation\"\n",
    "# get every partition data\n",
    "OBESITY_attr_dir = [] \n",
    "OBESITY_attr_dir.append(os.path.join(*[IG_map_dir, year,'partition0']))\n",
    "OBESITY_attr_dir.append(os.path.join(*[IG_map_dir, year,'partition1']))\n",
    "OBESITY_attr_dir.append(os.path.join(*[IG_map_dir, year,'partition2']))\n",
    "OBESITY_attr_dir.append(os.path.join(*[IG_map_dir, year,'partition3']))\n",
    "OBESITY_attr_dir.append(os.path.join(*[IG_map_dir, year,'partition4']))\n",
    "\n",
    "# gathering the name of subject files\n",
    "subject_file_list = []\n",
    "subject_list = [] \n",
    "for OBESITY_attr_dir_partition in OBESITY_attr_dir:\n",
    "    for file in  glob.glob(OBESITY_attr_dir_partition + '/*'): \n",
    "        subject_file_list.append(file)\n",
    "        subject_list.append(os.path.split(file)[-1].replace('.npy', ''))\n",
    "\n",
    "df_final = pd.DataFrame({'subjectkey': subject_list})\n",
    "for (mask_img_dir, mask_LUT_dir) in zip(mask_img_dir_list, mask_LUT_dir_list):\n",
    "    # calculating mean attribution score per ROI \n",
    "    df = extracting_score(mask_img_dir=mask_img_dir, subject_file_list=subject_file_list, subject_list=subject_list)\n",
    "\n",
    "    # indexing ROI name based on the number of ROI \n",
    "    with open(mask_LUT_dir, 'r') as file:\n",
    "        LUT = json.load(file) \n",
    "    df.columns = ['subjectkey'] + list(LUT.values())\n",
    "    \n",
    "    df_final = pd.merge(df_final, df, how='inner', on='subjectkey')\n",
    "\n",
    "# remove duplicated ROI\n",
    "df_final = df_final.drop(['Left Cerebral White Matter', 'Left Cerebral Cortex', 'Right Cerebral White Matter', 'Right Cerebral Cortex'], axis=1)\n",
    "\n",
    "\n",
    "# Summary feature importance \n",
    "ROI_list = list(df_final.keys()[1:])\n",
    "ROI_mean = [] \n",
    "ROI_std = []\n",
    "# getting mean score \n",
    "for ROI in ROI_list:\n",
    "    ROI_mean.append(np.mean(df_final[ROI]))\n",
    "    ROI_std.append(np.std(df_final[ROI]))\n",
    "ROI_mean_sorted = np.sort(ROI_mean)[::-1]\n",
    "ROI_mean_sorted = np.where(ROI_mean_sorted == 0, np.nan, ROI_mean_sorted) \n",
    "ROI_std_sorted = np.array(ROI_std)[np.argsort(ROI_mean)[::-1]]\n",
    "ROI_std_sorted = np.where(ROI_std_sorted == 0, np.nan, ROI_std_sorted)\n",
    "index_sorted = [index[i] for i in np.argsort(ROI_mean)[::-1]] \n",
    "\n",
    "df_result = pd.DataFrame(data=index_sorted, columns=['ROI'])\n",
    "df_result['attribution_mean'] = ROI_mean_sorted\n",
    "df_result['Rank'] = [i+1 for i in range(len(index_sorted))]\n",
    "\n",
    "\n",
    "df_result.to_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/paper/experiments/XAI/Feature_Importance_HarvardOxford_become_overweight_after2y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
