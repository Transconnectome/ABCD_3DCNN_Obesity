{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 'after1y'\n",
    "followup = '2_year_follow_up_y_arm_1' #options = ['baseline_year_1_arm_1', '1_year_follow_up_y_arm_1', '2_year_follow_up_y_arm_1']\n",
    "\n",
    "cat_cov = ['sex', 'abcd.site', 'race.ethnicity'] \n",
    "num_cov = ['age', 'BMI_sds_baseline', 'high.educ', 'income'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/fts0bv3j7jjb0263g94q1lbw0000gn/T/ipykernel_46259/638377041.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  original_phenotype['subjectkey'][i] = original_phenotype['subjectkey'][i].replace(\"_\", \"\")\n"
     ]
    }
   ],
   "source": [
    "original_phenotype_dir = '/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/statistics/ABCD Release4.0 Tabular dataset.csv'\n",
    "image_subject_list_dir = '/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/dnn/pretraining_subject_list.csv'\n",
    "if year == 'after1y':\n",
    "    phenotype_dir  = '/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/dnn/ABCD_phenotype_total_1years_become_overweight_10PS_stratified_partitioned_5fold.csv'\n",
    "    extract_list = ['subjectkey', 'BMI_sds_baseline', 'BMI_sds_1year','become_overweight', 'partition0', 'partition1', 'partition2', 'partition3', 'partition4']\n",
    "elif year == 'after2y': \n",
    "    phenotype_dir  = '/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/dnn/ABCD_phenotype_total_2years_become_overweight_10PS_stratified_partitioned_5fold.csv'\n",
    "    extract_list = ['subjectkey', 'BMI_sds_baseline', 'BMI_sds_2year','become_overweight', 'partition0', 'partition1', 'partition2', 'partition3', 'partition4']\n",
    "\n",
    "image_subject_list = pd.read_csv(image_subject_list_dir)['subjectkey']\n",
    "phenotype = pd.read_csv(phenotype_dir)\n",
    "phenotype = pd.merge(phenotype, image_subject_list, how='inner', on='subjectkey')\n",
    "original_phenotype = pd.read_csv(original_phenotype_dir)\n",
    "original_phenotype = original_phenotype[original_phenotype['eventname'] == followup].reset_index()\n",
    "for i in range(len(original_phenotype)): \n",
    "    original_phenotype['subjectkey'][i] = original_phenotype['subjectkey'][i].replace(\"_\", \"\")\n",
    "phenotype_final_tmp = pd.merge(original_phenotype, phenotype[extract_list], how='inner', on='subjectkey')\n",
    "phenotype_final_tmp = phenotype_final_tmp[phenotype_final_tmp['become_overweight'] == 1]\n",
    "\n",
    "phenotype = pd.DataFrame()\n",
    "for i in range(5): \n",
    "    phenotype = pd.concat([phenotype,  phenotype_final_tmp[phenotype_final_tmp['partition%s' % i] == 'test']])\n",
    "phenotype = phenotype.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'M']\n",
      "[224 249]\n",
      "52.64270613107822\n"
     ]
    }
   ],
   "source": [
    "index, count = pd.value_counts(phenotype['sex']).index,  pd.value_counts(phenotype['sex']).values\n",
    "index, count = np.sort(index), count[np.argsort(index)]\n",
    "print(index)\n",
    "print(count)\n",
    "print(count[1] / np.sum(count) * 100)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BMI sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20098287083091\n"
     ]
    }
   ],
   "source": [
    "if followup == 'baseline_year_1_arm_1':\n",
    "    print(np.median(phenotype['BMI_sds_baseline']))\n",
    "elif followup == '1_year_follow_up_y_arm_1': \n",
    "    if year == 'after1y': \n",
    "        print(np.median(phenotype['BMI_sds_1year']))\n",
    "    elif year == 'after2y':\n",
    "        tmp = pd.read_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/dnn/ABCD_phenotype_total_1years_become_overweight_10PS_stratified_partitioned_5fold.csv')\n",
    "        phenotype_tmp = pd.merge(phenotype, tmp[['subjectkey', 'BMI_sds_1year']], how='inner', on='subjectkey')\n",
    "        print(np.median(phenotype_tmp['BMI_sds_1year']))\n",
    "elif followup == '2_year_follow_up_y_arm_1': \n",
    "    if year == 'after1y': \n",
    "        tmp = pd.read_csv('/Users/wangheehwan/Desktop/CNN_for_BMI/paper/data/dnn/ABCD_phenotype_total_2years_become_overweight_10PS_stratified_partitioned_5fold.csv')\n",
    "        phenotype_tmp = pd.merge(phenotype, tmp[['subjectkey', 'BMI_sds_2year']], how='inner', on='subjectkey')\n",
    "        print(np.median(phenotype_tmp['BMI_sds_2year']))\n",
    "    elif year == 'after2y':\n",
    "        print(np.median(phenotype['BMI_sds_2year']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "print(np.median(phenotype['income'].dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maternal Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n"
     ]
    }
   ],
   "source": [
    "print(np.median(phenotype['high_educ'].dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Ancestry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[ 90 298]\n",
      "76.80412371134021\n"
     ]
    }
   ],
   "source": [
    "index, count = pd.value_counts(phenotype['euro']).index,  pd.value_counts(phenotype['euro']).values\n",
    "index, count = np.sort(index), count[np.argsort(index)]\n",
    "print(index)\n",
    "print(count)\n",
    "print(count[1] / np.sum(count) * 100)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
